{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#jelly","title":"Jelly","text":"<p>Jelly is a high-performance binary serialization format and streaming protocol for RDF. It is based on Protocol Buffers and gRPC, and has a JVM implementation that works with Apache Jena and RDF4J.</p> <ul> <li> <p> Stream any RDF data, fast</p> <p>Jelly is blazing-fast by design, and can work with streams of triples, graphs, datasets, and more</p> <p> Getting started</p> </li> <li> <p> Robust JVM implementation</p> <p>Fully-integrated support for Jelly in Apache Jena and RDF4J with maximum performance</p> <p> Jelly-JVM</p> </li> <li> <p> End-to-end streaming</p> <p>Jelly comes with a gRPC protocol and can work with Kafka, MQTT, and others</p> <p> User guide</p> <p> Streaming with Jelly-JVM</p> </li> <li> <p> Open specification</p> <p>Everything is open-source and well-documented to help you get started</p> <p> Protocol specification</p> </li> </ul>"},{"location":"#how-fast-is-it","title":"How fast is it?","text":"<p>Fast. Jelly was specifically designed to serialize and deserialize streams of RDF data faster than N-Triples or other binary formats, while being more compact than Turtle.</p> <p>The benchmarks below were performed on streams of RDF graphs or datasets, but Jelly is also good at handling streams of triples or quads (\"classic\" serialization). See: more benchmark results and details about the benchmark setup.</p> Serialization speed of a stream of RDF graphs or RDF datasets, averaged over 13 datasets (RiverBench 2.1.0 profile <code>stream-mixed-rdfstar</code>, task <code>stream-serialization-throughput</code>).* Partial results for RDF/XML and JSON-LD (some datasets not supported).More details about the benchmark. Deserialization (parsing) speed of a stream of RDF graphs or RDF datasets, averaged over 13 datasets (RiverBench 2.1.0 profile <code>stream-mixed-rdfstar</code>, task <code>stream-deserialization-throughput</code>).* Partial results for RDF/XML and JSON-LD (some datasets not supported).More details about the benchmark."},{"location":"#see-also","title":"See also","text":"<ul> <li>User guide</li> <li>Performance benchmarks</li> <li>Protocol specification</li> <li>Contributing to Jelly</li> <li>Code on GitHub: protocol definition, JVM implementation, website</li> <li>Licensing and citation</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>Jelly is an open project \u2013 you are welcome to submit issues, pull requests, or just ask questions.</p>"},{"location":"contributing/#contributing-to-the-jelly-specification","title":"Contributing to the Jelly specification","text":"<p>The Jelly Protocol Buffers and gRPC definitions are in the jelly-protobuf repository. If you want to contribute to the specification, it is strongly recommended that you first open an issue there to discuss your idea.</p> <p>The specification documents are edited in the same way as other documentation pages. See the next section for details.</p>"},{"location":"contributing/#editing-documentation","title":"Editing documentation","text":"<p>The documentation is written in Markdown and built using MkDocs, using Material for MkDocs.</p> <p>To edit a documentation page, simply click the  button in the top-right of the page:</p> <p></p> <p>It will take you to GitHub, where you can edit the Markdown file and submit a pull request. You can also clone the repository and edit the files locally. The source files are in the <code>docs</code> directory.</p> <p>Note: the <code>reference.md</code> file is automatically generated from the Jelly Protocol Buffers definitions. Do not edit it directly.</p>"},{"location":"contributing/#macros","title":"Macros","text":"<p>The documentation makes use of several macros for generating links, displaying the software version, etc. The macros are used in the Markdown files like this:</p> <pre><code>**Version**: {{ proto_version() }}\n</code></pre> <p>Which yields: </p> <p>Version: 1.0.0</p> <p>The list of available macros can be found in the <code>main.py</code> file in the root of the repository.</p>"},{"location":"contributing/#local-testing-of-the-website","title":"Local testing of the website","text":"<p>Install the project's dependencies from <code>requirements.txt</code> (preferably in a virtual environment). Then, run <code>mkdocs serve</code> to compile the docs and serve them locally for testing.</p> <pre><code># Create a virtual environment \u2013 use your preferred tool here\npython3 -m venv venv\nsource venv/bin/activate\n\n# Install dependencies\npip install -r requirements.txt\n\n# Run the local server\nmkdocs serve\n</code></pre>"},{"location":"contributing/#making-a-jelly-protocol-release","title":"Making a Jelly protocol release","text":"<p>Jelly protocol releases are handled from the <code>jelly-protobuf</code> repository. To make a new tagged release, follow these steps:</p> <ol> <li>Clone the <code>jelly-protobuf</code> repository.</li> <li>Make sure you are on the <code>main</code> branch and that it is up-to-date: <code>git checkout main &amp;&amp; git pull</code></li> <li>Create a new tag for the release. For example, for version 1.2.3: <code>git tag v1.2.3</code></li> <li>Push the tag to GitHub: <code>git push origin v1.2.3</code></li> </ol> <p>The CI/CD pipeline will automatically pick up the new tag and make a tagged release of the documentation, including the protocol specification. The spec pages use macros to display the current version, so they will be updated automatically.</p> <p>After a new protocol release, you should also update the implementations to use it.</p>"},{"location":"contributing/#further-reading","title":"Further reading","text":"<ul> <li>Material for MkDocs reference</li> <li>MkDocs documentation</li> <li>Macro plugin documentation</li> </ul>"},{"location":"contributing/#editing-jelly-jvm-documentation","title":"Editing Jelly-JVM documentation","text":"<p>Use the exact same process as for the website documentation. The Jelly-JVM documentation sources are in the <code>jelly-jvm</code> repository, <code>docs/docs</code> directory.</p>"},{"location":"contributing/#contributing-to-jelly-implementations","title":"Contributing to Jelly implementations","text":""},{"location":"contributing/#jelly-jvm","title":"Jelly-JVM","text":"<ul> <li>Jelly-JVM contributing page</li> <li>Jelly-JVM documentation includes the developer guide, explaining the technical aspects of contributing to it.</li> <li>GitHub repository</li> <li>Issue tracker</li> </ul>"},{"location":"contributing/#see-also","title":"See also","text":"<ul> <li>License and citation</li> <li>User guide</li> <li>Applications using Jelly</li> </ul>"},{"location":"licensing/","title":"Licensing and citation","text":"<ul> <li>The Jelly Protocol Buffers and gRPC definitions are licensed under the Apache License 2.0.</li> <li>The documentation of Jelly (this website) is licensed under the Creative Commons Attribution 4.0 license.</li> <li>The Jelly-JVM implementation is licensed under the Apache License 2.0.</li> </ul>"},{"location":"licensing/#attribution-citation","title":"Attribution / citation","text":"<p>If you use Jelly or Jelly-JVM in your research, please the most recent paper about Jelly:</p> <p>Sowi\u0144ski, P., Wasielewska-Michniewska, K., Ganzha, M., &amp; Paprzycki, M. (2022, October). Efficient RDF streaming for the edge-cloud continuum. In 2022 IEEE 8th World Forum on Internet of Things (WF-IoT) (pp. 1-8). IEEE.</p> <p>Or use this BibTeX entry:</p> <pre><code>@inproceedings{sowinski2022efficient,\n  title={Efficient RDF streaming for the edge-cloud continuum},\n  author={Sowi{\\'n}ski, Piotr and Wasielewska-Michniewska, Katarzyna and Ganzha, Maria and Paprzycki, Marcin and others},\n  booktitle={2022 IEEE 8th World Forum on Internet of Things (WF-IoT)},\n  pages={1--8},\n  year={2022},\n  organization={IEEE},\n  doi={10.1109/WF-IoT54382.2022.10152225}\n}\n</code></pre> <p>This paper describes an earlier version of Jelly from 2022. A new paper is in preparation.</p>"},{"location":"licensing/#jelly-maintainer","title":"Jelly maintainer","text":"<p>Jelly was created and is maintained by Piotr Sowi\u0144ski (Ostrzyciel) \u2013 GitHub.</p> <p></p>"},{"location":"licensing/#see-also","title":"See also","text":"<ul> <li>Contributing to Jelly</li> <li>Applications using Jelly</li> </ul>"},{"location":"performance/","title":"Performance benchmarks","text":"<p>The following results were obtained by benchmarking Jelly-JVM against serializations built into Apache Jena (including binary formats).</p> <p>The benchmarks were performed on two kinds of RDF streams (according to the RDF-STaX taxonomy):</p> <ul> <li>Flat RDF streams \u2013 streams of RDF triples or quads. This is the \"classic\" serialization \u2013 equivalent to, for example N-Triples or N-Quads.</li> <li>Grouped RDF streams \u2013 streams of RDF graphs or datasets.</li> </ul> <p>Jelly has a major performance advantage especially in grouped RDF streams. This is mostly due to Jelly being the only tested serialization that natively supports grouped RDF streams. Because of this, Jelly can exploit the repeating terms, prefixes, and structures in the stream to achieve much better compression and serialization speed.</p> <p>If you are only interested in parsing/writing a single graph or dataset, look at the flat streaming results.</p>"},{"location":"performance/#benchmark-setup","title":"Benchmark setup","text":"<p>All benchmarks presented here were performed using the RiverBench benchmark suite, version 2.1.0. Out of the 13 used datasets (all datasets available in RiverBench 2.1.0), 1 used RDF-star, and 3 included RDF quads/datasets. You can find the links to the specific used RiverBench profiles and tasks in the results below.</p> <p>The benchmarks were executed using this code (Apache 2.0) in a JVM with options: <code>-Xms1G -Xmx32G</code>. The large heap size was necessary to fit the benchmark data in memory, making the benchmark independent of disk I/O.</p> <p>Hardware: AMD Ryzen 9 7900 (12-core, 24-thread, 5.0 GHz); 64 GB RAM (DDR5 5600 MT/s). The disk was not used during the benchmarks (all data was in memory). The throughput benchmarks are single-threaded, but the JVM was allowed to use all available cores for garbage collection, JIT compilation, and other tasks.</p> <p>Software: Linux kernel 6.8.12, Oracle GraalVM 22.0.2+9, Apache Jena 5.0.0, Jelly-JVM 0.14.2 (equivalent to Jelly-JVM 1.0.0).</p>"},{"location":"performance/#tested-methods","title":"Tested methods","text":"<ul> <li>W3C RDF/XML (Apache Jena 5.0.0, <code>RDFXML_PLAIN</code>)</li> <li>W3C N-Triples / N-Quads (Apache Jena 5.0.0, <code>NTRIPLES</code> and <code>NQUADS</code>)</li> <li>W3C JSON-LD (Apache Jena 5.0.0, <code>JSONLD_PLAIN</code>)</li> <li>W3C Turtle / TriG (Apache Jena 5.0.0)<ul> <li>In grouped streaming, the default (<code>TURTLE_PRETTY</code> and <code>TRIG_PRETTY</code>) Turtle/TriG variant was used. </li> <li>In flat streaming, the <code>TURTLE_BLOCKS</code> and <code>TRIG_BLOCKS</code> variant was used. See Jena's documentation on streaming writers for more details.</li> </ul> </li> <li>Jena's RDF binary Protobuf format (Apache Jena 5.0.0, <code>RDF_PROTO</code>)</li> <li>Jena's RDF binary Thrift format (Apache Jena 5.0.0, <code>RDF_THRIFT</code>)</li> <li>Jelly (Jelly-JVM 0.14.2, \"big\" preset)     <pre><code>max_name_table_size = 4000;\nmax_prefix_table_size = 150;\nmax_datatype_table_size = 32;\n</code></pre></li> <li>Jelly without prefix compression (Jelly-JVM 0.14.2, \"big\" preset with prefix table disabled)     <pre><code>max_name_table_size = 4000;\nmax_prefix_table_size = 0;  // Prefix table disabled\nmax_datatype_table_size = 32;\n</code></pre></li> </ul>"},{"location":"performance/#results","title":"Results","text":"<p>Warning</p> <p>The results below were averaged over all datasets used in the benchmarks. For RDF/XML and JSON-LD the results are incomplete due to missing support for some datasets. For them, only the datasets that were successfully processed are included in the averages.</p> <p>RDF/XML failed on 5 out of 13 datasets due to lack of support for RDF datasets (<code>assist-iot-weather-graphs</code>, <code>citypulse-graphs</code>, <code>nanopubs</code>), RDF-star (<code>yago-annotated-facts</code>), and no support for encoding ASCII control characters (<code>politiquices</code> \u2013 see RiverBench documentation for more details).</p> <p>JSON-LD failed on 1 out of 13 datasets due to lack of support for RDF-star (<code>yago-annotated-facts</code>).</p>"},{"location":"performance/#serialized-size","title":"Serialized size","text":"<ul> <li>RiverBench task: <code>stream-compression</code> (2.1.0)</li> <li>RiverBench profile: <code>stream-mixed-rdfstar</code> (2.1.0)</li> <li>The entire (full-length) datasets were used for this benchmark.</li> <li>The data was serialized to a byte-counting output stream and then discarded.</li> </ul> Relative serialized representation size of a stream of RDF graphs or RDF datasets, geometric mean over all datasets. N-Triples/N-Quads was used as the baseline (100%).* Partial results for RDF/XML and JSON-LD (some datasets not supported). <p>Note that the results for the equivalent flat streaming task (<code>flat-compression</code>) would be almost identical for natively streaming formats: N-Triples/N-Quads, Jena's RDF binary Protobuf, Jena's RDF binary Thrift, and Jelly. The difference would be on the order of single bytes per RDF graph/dataset.</p>"},{"location":"performance/#flat-streaming-serialization-throughput","title":"Flat streaming serialization throughput","text":"<ul> <li>RiverBench task: <code>flat-serialization-throughput</code> (2.1.0)</li> <li>RiverBench profile: <code>flat-mixed-rdfstar</code> (2.1.0)</li> <li>The first 5,000,000 statements of each dataset were used for this benchmark.</li> <li>Each method/dataset combination was run 15 times, the first 5 runs were discarded to account for JVM warmup, and the remaining 10 runs were averaged.</li> <li>The data was preloaded into memory and serialized to a null output stream.</li> </ul> Serialization speed of a stream of RDF triples or quads, averaged over all datasets. <p>Jelly achieves very similar results to Jena's binary formats here. However, it should be noted that the Jena formats feature no compression at all, and Jelly is much more compact (see serialized size).</p>"},{"location":"performance/#flat-streaming-deserialization-throughput","title":"Flat streaming deserialization throughput","text":"<ul> <li>RiverBench task: <code>flat-deserialization-throughput</code> (2.1.0)</li> <li>RiverBench profile: <code>flat-mixed-rdfstar</code> (2.1.0)</li> <li>The first 5,000,000 statements of each dataset were used for this benchmark.</li> <li>Each method/dataset combination was run 15 times, the first 5 runs were discarded to account for JVM warmup, and the remaining 10 runs were averaged.</li> <li>Before running the benchmark, the data was serialized to a single byte array and then deserialized from it. The deserializer was emitting only a stream of triples/quads, without any further processing.</li> </ul> Deserialization (parsing) speed of a stream of RDF triples or quads, averaged over all datasets."},{"location":"performance/#grouped-streaming-serialization-throughput","title":"Grouped streaming serialization throughput","text":"<ul> <li>RiverBench task: <code>stream-serialization-throughput</code> (2.1.0)</li> <li>RiverBench profile: <code>stream-mixed-rdfstar</code> (2.1.0)</li> <li>The first 100,000 stream elements of each dataset were used for this benchmark.</li> <li>Each method/dataset combination was run 15 times, the first 5 runs were discarded to account for JVM warmup, and the remaining 10 runs were averaged.</li> <li>The data was preloaded into memory and serialized to a null output stream.</li> </ul> Serialization speed of a stream of RDF graphs or RDF datasets, averaged over all datasets.* Partial results for RDF/XML and JSON-LD (some datasets not supported)."},{"location":"performance/#grouped-streaming-deserialization-throughput","title":"Grouped streaming deserialization throughput","text":"<ul> <li>RiverBench task: <code>stream-deserialization-throughput</code> (2.1.0)</li> <li>RiverBench profile: <code>stream-mixed-rdfstar</code> (2.1.0)</li> <li>The first 100,000 stream elements of each dataset were used for this benchmark.</li> <li>Each method/dataset combination was run 15 times, the first 5 runs were discarded to account for JVM warmup, and the remaining 10 runs were averaged.</li> <li>Before running the benchmark, the data was serialized to a list of byte arrays (one array per stream element) and then deserialized from it. The deserializer was emitting only a stream of triples/quads, without any further processing.</li> </ul> Deserialization (parsing) speed of a stream of RDF graphs or RDF datasets, averaged over all datasets.* Partial results for RDF/XML and JSON-LD (some datasets not supported)."},{"location":"performance/#see-also","title":"See also","text":"<ul> <li>Benchmark code</li> <li>RiverBench benchmark suite</li> <li>Jelly-JVM \u2013 the Jelly implementation used in the benchmarks</li> <li>User guide</li> </ul>"},{"location":"use-cases/","title":"Applications using Jelly","text":"<p>If you are using Jelly in your project, we would be glad to list it here! Please open an issue or open a pull request with the information on your use case.</p>"},{"location":"use-cases/#jelly-jvm","title":"Jelly-JVM","text":"<ul> <li>RiverBench benchmark suite.<ul> <li>Jelly is used as one of the serialization formats for distributing datasets in RiverBench.</li> <li>Jelly is also used for distributing the RDF metadata of benchmark datasets, tasks, and other resources.</li> <li>This is implemented in the ci-worker application \u2013 a Scala 3 program making heavy use of Jelly-JVM's streaming capabilities.</li> </ul> </li> <li>Jelly-JVM benchmark code. This code was used to produce the results seen on the performance page.</li> <li>Not released publicly yet \u2013 stay tuned! A Scala 2 application using Jelly over Kafka, MQTT, and gRPC (full streaming protocol). </li> </ul>"},{"location":"use-cases/#see-also","title":"See also","text":"<ul> <li>User guide</li> <li>Licensing and citation</li> </ul>"},{"location":"user-guide/","title":"Jelly user guide","text":"<p>Jelly is a high-performance protocol for streaming and non-streaming RDF data. It is designed to be simple, fast, and easy to implement. This guide will help you get started with Jelly.</p> <p>Jelly uses Protocol Buffers 3 as the basis of its serialization. This means that you can quickly create a new Jelly implementation using code generation. You can also use an existing implementation, such as the JVM (Scala) implementation.</p>"},{"location":"user-guide/#what-can-it-do","title":"What can it do?","text":"<p>Jelly is designed to be a protocol for streaming RDF data, but it can also be used with \"classic\", static RDF data. The main design goals of Jelly are speed, simplicity, and wide coverage of use cases. </p> <ul> <li>Jelly can work with any RDF data, including RDF-star, RDF 1.1, and generalized RDF.</li> <li>Jelly can be used to represent streams of triples, quads, graphs, or datasets.</li> <li>Jelly can also be used to represent a single graph or dataset.</li> <li>Jelly can be used for streaming data over the network (e.g., with MQTT, Kafka, gRPC), but also for working with flat files.</li> <li>Jelly can compress RDF data on the fly, without having to know the data in advance.</li> <li>Jelly is super-fast and lightweight, scaling both down to embedded devices and up to high-performance servers.</li> </ul>"},{"location":"user-guide/#how-to-use-it","title":"How to use it?","text":"<p>To use Jelly you firstly need an implementation of the protocol. There is currently one implementation available: Jelly-JVM (Scala), which supports both Apache Jena and Eclipse RDF4J. It also has support for reactive streams and gRPC.</p> <p>The implementation will support several stream types and patterns that you can use. Which stream type you choose depends on your use case (see stream types below).</p> <p>All stream types use the same concept of stream frames \u2013 discrete elements into which the stream is divided. Each frame contains a number of rows, which are the actual RDF data (RDF triples, quads, etc.). Jelly does not enforce the semantics of stream frames, although it does have a mechanism to suggest to consumers and producers how should they understand the stream. Still, you can interpret the stream however you like.</p> <p>Why doesn't Jelly enforce the semantics of stream frames?</p> <p>There are many, many ways in which streams of RDF data can be used \u2013 there are different use cases, network protocols, QoS settings, ordering guarantees, stream semantics, etc. One stream is also often viewed from different perspectives by the different actors producing and consuming it. Picking and enforcing specific semantics for stream frames would hopelessly overcomplicate the protocol and make it less useful in some use cases.</p> <p>Jelly does have a system of logical stream types based on the RDF Stream Taxonomy (RDF-STaX), which can be used to suggest how the stream should be interpreted. However, these are just suggestions \u2013 you can interpret the stream however you like.</p>"},{"location":"user-guide/#stream-types","title":"Stream types","text":"<p>Jelly has the notions of physical stream types and logical stream types. The physical type tells you how Jelly sends the data on the wire, which is a technical detail. The logical type tells you how you should interpret the stream. Specifying the logical type is optional and is only a suggestion to the consumer. You can always interpret the stream however you like.</p> <p>There are three physical stream types in Jelly:</p> <ul> <li><code>TRIPLES</code>: Data is encoded using triple statements. There is no information about the graph name in this type of stream.</li> <li><code>QUADS</code>: Data is encoded using quad statements. Each quad has a graph name, which can also be empty for the default graph.</li> <li><code>GRAPHS</code>: Data is encoded using named graphs, where the graph name can also be empty for the default graph. Each named graph can contain multiple triples.</li> </ul> <p>As for logical stream types, they are taken directly from RDF-STaX \u2013 see the RDF-STaX website for a complete list of them. The following table summarizes which physical stream types may be used for each logical stream type. Please note that the table covers only the cases that are directly supported by the Jelly protocol specification and its official implementations.</p> RDF-STaX (logical type) / Physical type <code>TRIPLES</code> <code>QUADS</code> <code>GRAPHS</code> Graph stream Framed \u2718 \u2718 Subject graph stream Framed \u2718 \u2718 Dataset stream \u2718 Framed Framed Named graph stream \u2718 Framed Framed Timestamped named graph stream \u2718 Framed Framed Flat triple stream Continuous \u2718 \u2718 Flat quad stream \u2718 Continuous Continuous <p>The values in the table mean the following:</p> <ul> <li>Framed: Each stream frame corresponds to exactly one logical element of the stream type. For example, in a graph stream, each frame corresponds to a single RDF graph. This usage pattern is common in real-time streaming scenarios like IoT systems.</li> <li>Continuous: The stream is a continuous sequence of logical elements. For example, in a flat triple stream, the stream is just a sequence of triples.</li> <li>\u2718: The physical stream type is not directly supported for the logical stream type. However, you may still find a way to use it, depending on your use case.</li> </ul> <p>The flat logical stream types (flat RDF triple stream and flat RDF quad stream in RDF-STaX) can also be treated as a single RDF graph or RDF dataset, respectively.</p>"},{"location":"user-guide/#common-patterns-cookbook","title":"Common patterns cookbook","text":"<p>Below you will find some common patterns for using Jelly. These are just examples \u2013 you can use Jelly in many other ways. All of the presented patterns are supported in the Jelly-JVM (Scala) implementation with the Reactive Streaming module.</p>"},{"location":"user-guide/#flat-rdf-triple-stream-just-a-bunch-of-triples","title":"Flat RDF triple stream \u2013 \"just a bunch of triples\"","text":"<p>Let's say you want to stream a lot of triples from A to B \u2013 maybe you're doing some kind of data migration, or you're sending data to a data lake. You don't care about the graph they belong to \u2013 you just want to send a bunch of triples.</p> <p>This means you are using logically a flat RDF triple stream. It can be physically encoded as as <code>TRIPLES</code> stream, batching the triples into frames of an arbitrary size (let's say, 1000 triples each):</p> Example (click to expand) <ul> <li>Stream frame 1<ul> <li>Stream options</li> <li>Triple 1</li> <li>Triple 2</li> <li>...</li> <li>Triple 1000</li> </ul> </li> <li>Stream frame 2<ul> <li>Triple 1001</li> <li>Triple 1002</li> <li>...</li> <li>Triple 2000</li> </ul> </li> <li>...</li> </ul> <p>You can then send these frames one-by-one over gRPC or Kafka, or write them to a file. The consumer will be able to read the triples one frame at a time, without having to know how many triples there are in total.</p>"},{"location":"user-guide/#rdf-graph-stream","title":"RDF graph stream","text":"<p>In this case we have (for example) an IoT sensor that periodically emits an RDF graph that describes what the sensor saw (something like SOSA/SSN). The graphs may be of different sizes (depending on what the sensor saw) and they can be emitted at different rates (depending on how often the sensor is triggered). We want to stream these graphs to a server that will process them in real-time with no additional latency.</p> <p>This means you are using logically an RDF graph stream. You can encode it as a <code>TRIPLES</code> stream, where the stream frames correspond to different unnamed (default) graphs:</p> Example (click to expand) <ul> <li>Stream frame 1<ul> <li>Stream options</li> <li>Triple 1 (of graph 1)</li> <li>Triple 2 (of graph 1)</li> <li>...</li> <li>Triple 134 (of graph 1)</li> </ul> </li> <li>Stream frame 2<ul> <li>Triple 1 (of graph 2)</li> <li>Triple 2 (of graph 2)</li> <li>...</li> <li>Triple 97 (of graph 2)</li> </ul> </li> <li>...</li> </ul> <p>The consumer will be able to read the graphs one frame at a time, without having to know how many graphs there are in total.</p> <p>RiverBench uses this pattern for distributing its triple streams (see example). Note that in RiverBench the stream may be equivalently considered \"just a bunch of triples\" \u2013 the serialization is the same, it only depends on the interpretation on the side of the consumer.</p>"},{"location":"user-guide/#flat-rdf-quad-stream-just-a-bunch-of-quads","title":"Flat RDF quad stream \u2013 \"just a bunch of quads\"","text":"<p>You want to stream a lot of quads \u2013 similar to the \"just a bunch of triples\" case above, but you also want to include the graph node. This is logically a flat RDF quad stream. It can be physically encoded as a <code>QUADS</code> stream, batching the quads into frames of an arbitrary size (let's say, 1000 quads each):</p> Example (click to expand) <ul> <li>Stream frame 1<ul> <li>Stream options</li> <li>Quad 1</li> <li>Quad 2</li> <li>...</li> <li>Quad 1000</li> </ul> </li> <li>Stream frame 2<ul> <li>Quad 1001</li> <li>Quad 1002</li> <li>...</li> <li>Quad 2000</li> </ul> </li> <li>...</li> </ul> <p>The mechanism is exactly the same as with a flat RDF triple stream.</p>"},{"location":"user-guide/#flat-rdf-quad-stream-as-graphs","title":"Flat RDF quad stream (as <code>GRAPHS</code>)","text":"<p>This a slightly different take on the problem of \"just a bunch of quads\" \u2013 you also want to transmit what is essentially a single RDF dataset, but instead of sending individual quads, you want to send it graph-by-graph. This makes most sense if your data changes on a per-graph basis, or you are streaming a static RDF dataset.</p> <p>This is logically again a flat RDF quad stream, but it can be physically encoded as a <code>GRAPHS</code> stream, batching the triples in the graphs into frames of an arbitrary size (let's say, 1000 triples each):</p> Example (click to expand) <ul> <li>Stream frame 1<ul> <li>Stream options</li> <li>Start graph (named 1)</li> <li>Triple 1 (of graph 1)</li> <li>Triple 2 (of graph 1)</li> <li>...</li> <li>Triple 134 (of graph 1)</li> <li>End graph</li> <li>Start graph (named 2)</li> <li>Triple 1 (of graph 2)</li> <li>Triple 2 (of graph 2)</li> <li>...</li> <li>Triple 97 (of graph 2)</li> </ul> </li> <li>Stream frame 2<ul> <li>Triple 98 (of graph 2)</li> <li>...</li> <li>Triple 130 (of graph 2)</li> <li>End graph</li> <li>Start graph (named 3)</li> <li>Triple 1 (of graph 3)</li> <li>Triple 2 (of graph 3)</li> <li>...</li> <li>Triple 77 (of graph 3)</li> <li>End graph</li> <li>Start graph (named 4)</li> <li>Triple 1 (of graph 4)</li> <li>Triple 2 (of graph 4)</li> <li>...</li> <li>Triple 21 (of graph 4)</li> <li>End graph</li> </ul> </li> <li>...</li> </ul> <p>Notice that one named graph can span multiple stream frames, and one stream frame can contain multiple graphs. The consumer will be able to read the graphs one frame at a time, without having to know how many graphs there are in total.</p>"},{"location":"user-guide/#rdf-dataset-stream-as-quads","title":"RDF dataset stream (as <code>QUADS</code>)","text":"<p>You want to stream RDF datasets \u2013 similar to the \"a stream of graphs\" case above, but your elements are entire datasets. This is logically an RDF dataset stream, which can be physically encoded as a <code>QUADS</code> stream, where the stream frames correspond to different datasets:</p> Example (click to expand) <ul> <li>Stream frame 1<ul> <li>Stream options</li> <li>Quad 1 (of dataset 1)</li> <li>Quad 2 (of dataset 1)</li> <li>...</li> <li>Quad 454 (of dataset 1)</li> </ul> </li> <li>Stream frame 2<ul> <li>Quad 1 (of dataset 2)</li> <li>Quad 2 (of dataset 2)</li> <li>...</li> <li>Quad 323 (of dataset 2)</li> </ul> </li> <li>...</li> </ul> <p>The mechanism is exactly the same as with a triple stream of graphs.</p> <p>RiverBench uses this pattern for distributing its RDF dataset streams (see example). Note that in RiverBench the stream may be equivalently considered a flat RDF quad stream \u2013 the serialization is the same, it only depends on the interpretation on the side of the consumer.</p>"},{"location":"user-guide/#rdf-dataset-stream-as-graphs","title":"RDF dataset stream (as <code>GRAPHS</code>)","text":"<p>You want to stream RDF datasets or a subclass of them \u2013 for example timestamped named graphs, using the RSP Data Model, where each stream element is a named graph and a bunch of statements about this graph in the default graph. This can be physically encoded as a <code>GRAPHS</code> stream, where the stream frames correspond to different datasets:</p> Example (click to expand) <ul> <li>Stream frame 1<ul> <li>Stream options</li> <li>Start graph (default)</li> <li>Triple 1 (of default graph, dataset 1)</li> <li>Triple 2 (of default graph, dataset 1)</li> <li>...</li> <li>Triple 134 (of default graph, dataset 1)</li> <li>End graph</li> <li>Start graph (named)</li> <li>Triple 1 (of named graph, dataset 1)</li> <li>Triple 2 (of named graph, dataset 1)</li> <li>...</li> <li>Triple 97 (of named graph, dataset 1)</li> <li>End graph</li> </ul> </li> <li>Stream frame 2<ul> <li>Start graph (default)</li> <li>Triple 1 (of default graph, dataset 2)</li> <li>Triple 2 (of default graph, dataset 2)</li> <li>...</li> <li>Triple 77 (of default graph, dataset 2)</li> <li>End graph</li> <li>Start graph (named)</li> <li>Triple 1 (of named graph, dataset 2)</li> <li>Triple 2 (of named graph, dataset 2)</li> <li>...</li> <li>Triple 21 (of named graph, dataset 2)</li> <li>End graph</li> </ul> </li> <li>...</li> </ul> <p>Of course each stream frame could contain more than one named graph, and the graphs can be of different sizes.</p>"},{"location":"user-guide/#ordering-and-delivery-guarantees","title":"Ordering and delivery guarantees","text":"<p>To be able to compress RDF streams on-the-fly, Jelly requires that stream frames are kept strictly in order (see also the spec). This is because the compression algorithm updates its lookup tables dynamically over the course of the stream, and a given frame depends on the lookups defined in previous frames. If the frames are out of order, the compression may fail.</p> <p>There are use cases where it's hard to guarantee strict ordering of messages, such as IoT messaging (e.g., MQTT with QoS 0) or high-throughput streams with parallel partitions (e.g., Kafka). In these cases you may want to employ one of these strategies:</p> <ul> <li>Emit shared lookup tables at the start of the stream: If you know the vocabulary of the stream, you can emit most of the content of the lookup tables at the start of the stream, and then only update the lookup elements that vary frame-to-frame, keeping the updates local to the frame. This strategy is especially useful in IoT scenarios, where the vocabulary is usually known in advance. You don't need to modify the consumer in this case.<ul> <li>A variation of this strategy is to communicate the lookup tables over a separate channel before starting the stream. This is useful if you can't guarantee that the lookup tables will be delivered before the stream frames.</li> </ul> </li> <li>Use a \"frame ID\" to keep track of the order: If you can't guarantee the order of the frames, you can add a \"frame ID\" to each frame, which will allow the consumer to reorder the frames before processing them. This strategy is useful in high-throughput scenarios, where you can't guarantee the order of the frames. You will need to modify the consumer to reorder the frames before processing them. However, handling failures in this scenario may be complicated.</li> <li>Use partitions that are guaranteed to be in-order: If you can't guarantee the order of the frames, you can use partitions that are guaranteed to be in-order (e.g., Kafka partitions). Then, each partition should have its own set of lookups (essentially treating each partition as a separate stream in Jelly's terms). This strategy is useful in high-throughput scenarios.</li> </ul> <p>Note that Jelly by default also assumes that frames are delivered at least once. At-least-once delivery is good enough (as long as the order is kept), as lookup updates are idempotent \u2013 you may only need to de-duplicate the frames afterwards. At-most-once delivery requires you to make the frames independent of each other, such as with the IoT strategy above.</p>"},{"location":"user-guide/#delimited-vs-non-delimited-jelly","title":"Delimited vs. non-delimited Jelly","text":"<p>Protobuf messages by default are not delimited. This means that when you serialize a Protobuf message (e.g., a Jelly stream frame), the serialization does not include any information about where the message ends. This is fine when there is something else telling the parser where the message ends \u2013 for example, when you're sending the message over a gRPC, Kafka, or MQTT stream, the streaming protocol tells the parser how long the message is. However, if you wanted to write multiple stream frames to a file, you would need to add some kind of delimiter between the frames \u2013 otherwise the parser would not know where one frame ends and the next one begins.</p> <p>So, to summarize:</p> Use case Jelly variant Description Jelly gRPC streaming protocol Non-delimited The gRPC protocol tells the parser how long the message is. Streaming with Kafka, MQTT, or similar Non-delimited The streaming protocol tells the parser how long the message is. Writing to a file Delimited You need to add a delimiter between the frames. Writing to a raw network socket Delimited You need to add a delimiter between the frames. <p>The delimited variant works by adding an integer before the stream frame that specifies the length of the frame, in bytes. That's it.</p> <p>You can read more about how this works in the serialization format specification.</p>"},{"location":"user-guide/#examples","title":"Examples","text":"<ul> <li>Jelly-JVM supports both variants, but uses them in different contexts. When writing to a Java byte stream (typically a file) with Apache Jena RIOT or RDF4J Rio, the delimited variant is used. In the gRPC protocol, the non-delimited variant is used.</li> <li>RiverBench publishes its RDF metadata and datasets as Jelly files. These files are always written using the delimited variant.</li> </ul>"},{"location":"user-guide/#implementing-jelly","title":"Implementing Jelly","text":"<p>Note</p> <p>This section is intended only for those who want to write a new Jelly implementation from scratch. It's much easier to use an existing implementation, such as the JVM (Scala) implementation.</p> <p>Implementing Jelly from scratch is greatly simplified by the existing Protobuf and RDF libraries. Essentially, the only thing you'll need to do is to glue them together:</p> <ul> <li>Find a Protobuf library for your language. You can find a list of official Protobuf implementations here and a list of community-maintained implementations here.</li> <li>Use the library to generate the code for the Jelly messages (this usually involves using <code>protoc</code>). You can find the Protobuf definitions in the jelly-protobuf repository.</li> <li>Find an RDF library for your language. You can find a list of RDF libraries here.</li> <li>Implement conversions to and/or from the RDF library's data structures. You can find an example of the conversion code in the Jelly-JVM (Scala) implementation (<code>core</code>, <code>jena</code>, and <code>rdf4j</code> modules).</li> <li>In the implementation follow the specification to ensure compatibility.</li> </ul> <p>That's it! You may also want to implement streaming facilities, such as Reactive Streams in Java/Scala. Implementing the gRPC publish/subscribe mechanism follows a very similar procedure \u2013 many Protobuf libraries have built-in support for gRPC with code generation.</p>"},{"location":"user-guide/#see-also","title":"See also","text":"<ul> <li>Jelly-JVM getting started guide</li> <li>Applications using Jelly</li> </ul>"},{"location":"specification/","title":"Jelly protocol specification","text":"<p>The Jelly protocol consists of two parts: the gRPC streaming protocol and the serialization format. The serialization format is the basis for Jelly, specifying how to turn RDF data into bytes and back. The gRPC streaming protocol defines a publish/subscribe mechanism for exchanging RDF data between a client and a server, using gRPC.</p> <p>See the user guide for a friendlier introduction to Jelly.</p> <p>See the specification pages for more details:</p> <ul> <li>Serialization format specification</li> <li>gRPC streaming protocol specification</li> <li>Protobuf reference</li> <li>Protobuf sources</li> <li>File extension and media type</li> </ul>"},{"location":"specification/media-type/","title":"File extension and media type","text":"<p>Jelly is not tied to any specific file extension and does not have a registered media type. However, you can use the following:</p> <ul> <li>File extension: <code>.jelly</code></li> <li>Media type: <code>application/x-jelly-rdf</code></li> </ul> <p>The files should be saved in the delimited variant of Jelly.</p>"},{"location":"specification/media-type/#see-also","title":"See also","text":"<ul> <li>Serialization format specification</li> </ul>"},{"location":"specification/protobuf-source/","title":"Protobuf sources","text":"<p>Below you will find the Protocol Buffers definitions for the Jelly serialization format and the Jelly gRPC streaming protocol. The original files are hosted on GitHub and all releases can be found here.</p> <p>Human-readable reference for these definitions can be found here.</p> <p>The following code is licensed under the Apache License, Version 2.0.</p>"},{"location":"specification/protobuf-source/#rdfproto","title":"<code>rdf.proto</code>","text":"<pre><code>syntax = \"proto3\";\npackage eu.ostrzyciel.jelly.core.proto.v1;\n\n// Jelly RDF serialization with Protocol Buffers.\n// Specification document: https://w3id.org/jelly/1.0.0/specification/serialization\n// Protocol version: 1.0.0\n\n// RDF IRIs\n// The IRIs are reconstructed by the consumer using the prefix and name\n// lookup tables.\nmessage RdfIri {\n  // 1-based, refers to an entry in the prefix lookup.\n  //\n  // 0 signifies \"use the same prefix_id as in the previous IRI\".\n  // For this to work, IRIs must be processed strictly in order: firstly by\n  // stream row, then by term (subject, predicate, object, graph). This also\n  // applies recursively to RDF-star quoted triples.\n  //\n  // If 0 appears in the first IRI of the stream (and in any subsequent IRI),\n  // this should be interpreted as an empty (\"\") prefix. This is for example\n  // used when the prefix lookup table is disabled.\n  uint32 prefix_id = 1;\n\n  // 1-based, refers to an entry in the name lookup.\n  //\n  // 0 signifies \"use the previous name_id + 1\". This requires the same order\n  // guarantees as prefixes.\n  //\n  // If 0 appears in the first IRI of the stream, it should be interpreted as\n  // name_id = 1.\n  uint32 name_id = 2;\n}\n\n// RDF literals\nmessage RdfLiteral {\n  // The lexical form of the literal (required).\n  string lex = 1;\n\n  // Literal kind \u2013 at most one of these field may be set.\n  // If none is set, then it's a simple literal.\n  oneof literalKind {\n    // Language-tagged string.\n    string langtag = 2;\n    // Typed literal. The datatype is a reference to an entry in the\n    // datatype lookup. This value is 1-based and the value of 0\n    // is invalid (in contrast to prefix_id and name_id in RdfIri).\n    uint32 datatype = 3;\n  }\n}\n\n// Empty message indicating the default RDF graph.\nmessage RdfDefaultGraph {\n}\n\n// RDF triple\n//\n// For each term (subject, predicate, object), the fields are repeated for\n// performance reasons. This is to avoid the need for boxing each term in a\n// separate message.\n//\n// Note: this message allows for representing generalized RDF triples (for\n// example, with literals as predicates). Whether this is used in the stream\n// is determined by the stream options (see RdfStreamOptions).\n//\n// If no field in a given oneof is set, the term is interpreted as a repeated\n// term \u2013 the same as the term in the same position in the previous triple.\n// In the first triple of the stream, all terms must be set.\n// All terms must also be set in quoted triples (RDF-star).\nmessage RdfTriple {\n  // Triple subject\n  oneof subject {\n    // IRI\n    RdfIri        s_iri = 1;\n    // Blank node\n    string        s_bnode = 2;\n    // Literal\n    // Only valid in a generalized RDF stream.\n    RdfLiteral    s_literal = 3;\n    // RDF-star quoted triple\n    RdfTriple     s_triple_term = 4;\n  }\n\n  // Triple predicate\n  oneof predicate {\n    // IRI\n    RdfIri        p_iri = 5;\n    // Blank node\n    // Only valid in a generalized RDF stream.\n    string        p_bnode = 6;\n    // Literal\n    // Only valid in a generalized RDF stream.\n    RdfLiteral    p_literal = 7;\n    // RDF-star quoted triple\n    RdfTriple     p_triple_term = 8;\n  }\n\n  // Triple object\n  oneof object {\n    // IRI\n    RdfIri        o_iri = 9;\n    // Blank node\n    string        o_bnode = 10;\n    // Literal\n    RdfLiteral    o_literal = 11;\n    // RDF-star quoted triple\n    RdfTriple     o_triple_term = 12;\n  }\n}\n\n// RDF quad\n//\n// Fields 1\u201312 are repeated from RdfTriple for performance reasons.\n//\n// Similarly to RdfTriple, this message allows for representing generalized\n// RDF quads (for example, with literals as predicates). Whether this is used\n// in the stream is determined by the stream options (see RdfStreamOptions).\n//\n// If no field in a given oneof is set, the term is interpreted as a repeated\n// term \u2013 the same as the term in the same position in the previous quad.\n// In the first quad of the stream, all terms must be set.\nmessage RdfQuad {\n  // Quad subject\n  oneof subject {\n    // IRI\n    RdfIri        s_iri = 1;\n    // Blank node\n    string        s_bnode = 2;\n    // Literal\n    // Only valid in a generalized RDF stream.\n    RdfLiteral    s_literal = 3;\n    // RDF-star quoted triple\n    RdfTriple     s_triple_term = 4;\n  }\n\n  // Quad predicate\n  oneof predicate {\n    // IRI\n    RdfIri        p_iri = 5;\n    // Blank node\n    // Only valid in a generalized RDF stream.\n    string        p_bnode = 6;\n    // Literal\n    // Only valid in a generalized RDF stream.\n    RdfLiteral    p_literal = 7;\n    // RDF-star quoted triple\n    RdfTriple     p_triple_term = 8;\n  }\n\n  // Quad object\n  oneof object {\n    // IRI\n    RdfIri        o_iri = 9;\n    // Blank node\n    string        o_bnode = 10;\n    // Literal\n    RdfLiteral    o_literal = 11;\n    // RDF-star quoted triple\n    RdfTriple     o_triple_term = 12;\n  }\n\n  // Quad graph\n  oneof graph {\n    // IRI\n    RdfIri           g_iri = 13;\n    // Blank node\n    string           g_bnode = 14;\n    // Default graph\n    RdfDefaultGraph  g_default_graph = 15;\n    // Literal \u2013 only valid for generalized RDF streams\n    RdfLiteral       g_literal = 16;\n  }\n}\n\n// Start of a graph in a GRAPHS stream\n//\n// In contrast to RdfQuad, setting the graph oneof to some value\n// is always required. No repeated terms are allowed.\nmessage RdfGraphStart {\n  oneof graph {\n    // IRI\n    RdfIri           g_iri = 1;\n    // Blank node\n    string           g_bnode = 2;\n    // Default graph\n    RdfDefaultGraph  g_default_graph = 3;\n    // Literal \u2013 only valid for generalized RDF streams\n    RdfLiteral       g_literal = 4;\n  }\n}\n\n// End of a graph in a GRAPHS stream\nmessage RdfGraphEnd {\n}\n\n// Entry in the name lookup table\nmessage RdfNameEntry {\n  // 1-based identifier\n  // If id=0, it should be interpreted as previous_id + 1.\n  // If id=0 appears in the first RdfNameEntry of the stream, it should be\n  // interpreted as 1.\n  uint32 id = 1;\n  // Value of the name (UTF-8 encoded)\n  string value = 2;\n}\n\n// Entry in the prefix lookup table\nmessage RdfPrefixEntry {\n  // 1-based identifier\n  // If id=0, it should be interpreted as previous_id + 1.\n  // If id=0 appears in the first RdfPrefixEntry of the stream, it should be\n  // interpreted as 1.\n  uint32 id = 1;\n  // Value of the prefix (UTF-8 encoded)\n  string value = 2;\n}\n\n// Entry in the datatype lookup table\nmessage RdfDatatypeEntry {\n  // 1-based identifier\n  // If id=0, it should be interpreted as previous_id + 1.\n  // If id=0 appears in the first RdfDatatypeEntry of the stream, it should be\n  // interpreted as 1.\n  uint32 id = 1;\n  // Value of the datatype (UTF-8 encoded)\n  string value = 2;\n}\n\n// RDF stream options\nmessage RdfStreamOptions {\n  // Name of the stream (completely optional).\n  // This may be used for, e.g., topic names in a pub/sub system.\n  string stream_name = 1;\n  // Type of the stream (required)\n  PhysicalStreamType physical_type = 2;\n  // Whether the stream may contain generalized triples, quads, or datasets\n  bool generalized_statements = 3;\n  // Whether the stream may contain RDF-star statements\n  bool rdf_star = 4;\n  // Maximum size of the name lookup table\n  uint32 max_name_table_size = 9;\n  // Maximum size of the prefix lookup table\n  uint32 max_prefix_table_size = 10;\n  // Maximum size of the datatype lookup table\n  uint32 max_datatype_table_size = 11;\n  // Logical (RDF-STaX-based) stream type\n  // In contrast to the physical type, this field is entirely optional.\n  LogicalStreamType logical_type = 14;\n  // Protocol version (required)\n  // For Jelly 1.0.x value must be 1.\n  // For custom extensions, the value must be 10000 or higher.\n  uint32 version = 15;\n}\n\n// Physical stream type\n// This determines how the data is encoded in the stream, not the logical\n// structure of the data. See LogicalStreamType for the latter.\nenum PhysicalStreamType {\n  // Unspecified stream type \u2013 invalid\n  PHYSICAL_STREAM_TYPE_UNSPECIFIED = 0;\n  // RDF triples\n  PHYSICAL_STREAM_TYPE_TRIPLES = 1;\n  // RDF quads\n  PHYSICAL_STREAM_TYPE_QUADS = 2;\n  // RDF triples grouped in graphs\n  PHYSICAL_STREAM_TYPE_GRAPHS = 3;\n}\n\n// Logical stream type, according to the RDF Stream Taxonomy (RDF-STaX).\n// Type 0 is reserved for the unspecified stream type.\n// The rest of the type numbers follow the taxonomical structure of RDF-STaX.\n// For example: 1 is a subtype of 0, 13 and 23 are subtypes of 3, \n// 114 is a subtype of 14, etc.\n// \n// Types 1\u20134 correspond to the four base concrete stream types. Their \n// subtypes can be in most cases simply processed in the same way as \n// the base types.\n// Therefore, implementations can take the modulo 10 of the stream \n// type to determine the base type of the stream and use this information \n// to select the appropriate processing logic.\n//\n// RDF-STaX version: 1.1.2\n// https://w3id.org/stax/1.1.2\n//\n// ^ The above URL is used to automatically determine the version of RDF-STaX\n// in the Jelly protocol specification. Please keep it up-to-date and in the\n// same format.\nenum LogicalStreamType {\n  // Unspecified stream type \u2013 invalid\n  LOGICAL_STREAM_TYPE_UNSPECIFIED = 0;\n  // Flat RDF triple stream\n  // https://w3id.org/stax/ontology#flatTripleStream\n  LOGICAL_STREAM_TYPE_FLAT_TRIPLES = 1;\n  // Flat RDF quad stream\n  // https://w3id.org/stax/ontology#flatQuadStream\n  LOGICAL_STREAM_TYPE_FLAT_QUADS = 2;\n  // RDF graph stream\n  // https://w3id.org/stax/ontology#graphStream\n  LOGICAL_STREAM_TYPE_GRAPHS = 3;\n  // RDF dataset stream\n  // https://w3id.org/stax/ontology#datasetStream\n  LOGICAL_STREAM_TYPE_DATASETS = 4;\n\n  // RDF subject graph stream (subtype of RDF graph stream)\n  // https://w3id.org/stax/ontology#subjectGraphStream\n  LOGICAL_STREAM_TYPE_SUBJECT_GRAPHS = 13;\n\n  // RDF named graph stream (subtype of RDF dataset stream)\n  // https://w3id.org/stax/ontology#namedGraphStream\n  LOGICAL_STREAM_TYPE_NAMED_GRAPHS = 14;\n  // RDF timestamped named graph stream (subtype of RDF dataset stream)\n  // https://w3id.org/stax/ontology#timestampedNamedGraphStream\n  LOGICAL_STREAM_TYPE_TIMESTAMPED_NAMED_GRAPHS = 114;\n}\n\n// RDF stream row\nmessage RdfStreamRow {\n  // Exactly one of these fields must be set.\n  oneof row {\n    // Stream options. Must occur at the start of the stream.\n    RdfStreamOptions options = 1;\n    // RDF triple statement.\n    // Valid in streams of physical type TRIPLES or GRAPHS.\n    RdfTriple triple = 2;\n    // RDF quad statement.\n    // Only valid in streams of physical type QUADS.\n    RdfQuad quad = 3;\n    // Graph boundary: ends the currently transmitted graph and starts a new one\n    // Only valid in streams of physical type GRAPHS.\n    RdfGraphStart graph_start = 4;\n    // Explicit end of a graph.\n    // Signals the consumer that the transmitted graph is complete.\n    // Only valid in streams of physical type GRAPHS.\n    RdfGraphEnd graph_end = 5;\n    // Entry in the name lookup table.\n    RdfNameEntry name = 9;\n    // Entry in the prefix lookup table.\n    RdfPrefixEntry prefix = 10;\n    // Entry in the datatype lookup table.\n    RdfDatatypeEntry datatype = 11;\n  }\n}\n\n// RDF stream frame \u2013 base message for RDF streams.\nmessage RdfStreamFrame {\n  // Stream rows\n  repeated RdfStreamRow rows = 1;\n}\n</code></pre>"},{"location":"specification/protobuf-source/#grpcproto","title":"<code>grpc.proto</code>","text":"<pre><code>syntax = \"proto3\";\npackage eu.ostrzyciel.jelly.core.proto.v1;\n\n// Jelly gRPC streaming protocol.\n// Specification document: https://w3id.org/jelly/1.0.0/specification/streaming\n// Protocol version: 1.0.0\n\nimport \"rdf.proto\";\n\n// Subscribe command sent by the client to the server.\nmessage RdfStreamSubscribe {\n  // The topic to which the client wants to subscribe (UTF-8 encoded).\n  string topic = 1;\n  // Optional: the stream options requested by the client.\n  // The server should respond with a stream that matches these options.\n  // In case that is not possible, the server must respond with the\n  // INVALID_ARGUMENT error.\n  RdfStreamOptions requested_options = 2;\n}\n\n// Acknowledgement of receiving a stream sent by the server to the client.\nmessage RdfStreamReceived {\n}\n\n// Pub/Sub service for RDF streams, to be implemented by the server.\nservice RdfStreamService {\n  // Subscribe to an RDF stream.\n  rpc SubscribeRdf (RdfStreamSubscribe) returns (stream RdfStreamFrame);\n  // Publish an RDF stream.\n  // In case the server cannot process the stream, it must respond with\n  // the INVALID_ARGUMENT error.\n  rpc PublishRdf (stream RdfStreamFrame) returns (RdfStreamReceived);\n}\n</code></pre>"},{"location":"specification/protobuf-source/#see-also","title":"See also","text":"<ul> <li>Jelly Protobuf reference</li> <li>Serialization format specification</li> <li>gRPC streaming protocol specification</li> </ul>"},{"location":"specification/reference/","title":"Protocol Documentation","text":""},{"location":"specification/reference/#table-of-contents","title":"Table of Contents","text":"<ul> <li> <p>grpc.proto</p> <ul> <li>RdfStreamReceived</li> <li> <p>RdfStreamSubscribe</p> </li> <li> <p>RdfStreamService</p> </li> </ul> </li> <li> <p>rdf.proto</p> <ul> <li>RdfDatatypeEntry</li> <li>RdfDefaultGraph</li> <li>RdfGraphEnd</li> <li>RdfGraphStart</li> <li>RdfIri</li> <li>RdfLiteral</li> <li>RdfNameEntry</li> <li>RdfPrefixEntry</li> <li>RdfQuad</li> <li>RdfStreamFrame</li> <li>RdfStreamOptions</li> <li>RdfStreamRow</li> <li> <p>RdfTriple</p> </li> <li> <p>LogicalStreamType</p> </li> <li>PhysicalStreamType</li> </ul> </li> <li> <p>Scalar Value Types</p> </li> </ul> <p></p> <p>Top</p>"},{"location":"specification/reference/#grpcproto","title":"grpc.proto","text":""},{"location":"specification/reference/#rdfstreamreceived","title":"RdfStreamReceived","text":"<p>Acknowledgement of receiving a stream sent by the server to the client.</p> <p></p>"},{"location":"specification/reference/#rdfstreamsubscribe","title":"RdfStreamSubscribe","text":"<p>Subscribe command sent by the client to the server.</p> Field Type Label Description topic string The topic to which the client wants to subscribe (UTF-8 encoded). requested_options RdfStreamOptions Optional: the stream options requested by the client. The server should respond with a stream that matches these options. In case that is not possible, the server must respond with the INVALID_ARGUMENT error. <p></p>"},{"location":"specification/reference/#rdfstreamservice","title":"RdfStreamService","text":"<p>Pub/Sub service for RDF streams, to be implemented by the server.</p> Method Name Request Type Response Type Description SubscribeRdf RdfStreamSubscribe RdfStreamFrame stream Subscribe to an RDF stream. PublishRdf RdfStreamFrame stream RdfStreamReceived Publish an RDF stream. In case the server cannot process the stream, it must respond with the INVALID_ARGUMENT error. <p></p> <p>Top</p>"},{"location":"specification/reference/#rdfproto","title":"rdf.proto","text":""},{"location":"specification/reference/#rdfdatatypeentry","title":"RdfDatatypeEntry","text":"<p>Entry in the datatype lookup table</p> Field Type Label Description id uint32 1-based identifier If id=0, it should be interpreted as previous_id + 1. If id=0 appears in the first RdfDatatypeEntry of the stream, it should be interpreted as 1. value string Value of the datatype (UTF-8 encoded) <p></p>"},{"location":"specification/reference/#rdfdefaultgraph","title":"RdfDefaultGraph","text":"<p>Empty message indicating the default RDF graph.</p> <p></p>"},{"location":"specification/reference/#rdfgraphend","title":"RdfGraphEnd","text":"<p>End of a graph in a GRAPHS stream</p> <p></p>"},{"location":"specification/reference/#rdfgraphstart","title":"RdfGraphStart","text":"<p>Start of a graph in a GRAPHS stream</p> <p>In contrast to RdfQuad, setting the graph oneof to some value is always required. No repeated terms are allowed.</p> Field Type Label Description g_iri RdfIri IRI g_bnode string Blank node g_default_graph RdfDefaultGraph Default graph g_literal RdfLiteral Literal \u2013 only valid for generalized RDF streams <p></p>"},{"location":"specification/reference/#rdfiri","title":"RdfIri","text":"<p>RDF IRIs The IRIs are reconstructed by the consumer using the prefix and name lookup tables.</p> Field Type Label Description prefix_id uint32 1-based, refers to an entry in the prefix lookup. 0 signifies \"use the same prefix_id as in the previous IRI\". For this to work, IRIs must be processed strictly in order: firstly by stream row, then by term (subject, predicate, object, graph). This also applies recursively to RDF-star quoted triples. If 0 appears in the first IRI of the stream (and in any subsequent IRI), this should be interpreted as an empty (\"\") prefix. This is for example used when the prefix lookup table is disabled. name_id uint32 1-based, refers to an entry in the name lookup. 0 signifies \"use the previous name_id + 1\". This requires the same order guarantees as prefixes. If 0 appears in the first IRI of the stream, it should be interpreted as name_id = 1. <p></p>"},{"location":"specification/reference/#rdfliteral","title":"RdfLiteral","text":"<p>RDF literals</p> Field Type Label Description lex string The lexical form of the literal (required). langtag string Language-tagged string. datatype uint32 Typed literal. The datatype is a reference to an entry in the datatype lookup. This value is 1-based and the value of 0 is invalid (in contrast to prefix_id and name_id in RdfIri). <p></p>"},{"location":"specification/reference/#rdfnameentry","title":"RdfNameEntry","text":"<p>Entry in the name lookup table</p> Field Type Label Description id uint32 1-based identifier If id=0, it should be interpreted as previous_id + 1. If id=0 appears in the first RdfNameEntry of the stream, it should be interpreted as 1. value string Value of the name (UTF-8 encoded) <p></p>"},{"location":"specification/reference/#rdfprefixentry","title":"RdfPrefixEntry","text":"<p>Entry in the prefix lookup table</p> Field Type Label Description id uint32 1-based identifier If id=0, it should be interpreted as previous_id + 1. If id=0 appears in the first RdfPrefixEntry of the stream, it should be interpreted as 1. value string Value of the prefix (UTF-8 encoded) <p></p>"},{"location":"specification/reference/#rdfquad","title":"RdfQuad","text":"<p>RDF quad</p> <p>Fields 1\u201312 are repeated from RdfTriple for performance reasons.</p> <p>Similarly to RdfTriple, this message allows for representing generalized RDF quads (for example, with literals as predicates). Whether this is used in the stream is determined by the stream options (see RdfStreamOptions).</p> <p>If no field in a given oneof is set, the term is interpreted as a repeated term \u2013 the same as the term in the same position in the previous quad. In the first quad of the stream, all terms must be set.</p> Field Type Label Description s_iri RdfIri IRI s_bnode string Blank node s_literal RdfLiteral Literal Only valid in a generalized RDF stream. s_triple_term RdfTriple RDF-star quoted triple p_iri RdfIri IRI p_bnode string Blank node Only valid in a generalized RDF stream. p_literal RdfLiteral Literal Only valid in a generalized RDF stream. p_triple_term RdfTriple RDF-star quoted triple o_iri RdfIri IRI o_bnode string Blank node o_literal RdfLiteral Literal o_triple_term RdfTriple RDF-star quoted triple g_iri RdfIri IRI g_bnode string Blank node g_default_graph RdfDefaultGraph Default graph g_literal RdfLiteral Literal \u2013 only valid for generalized RDF streams <p></p>"},{"location":"specification/reference/#rdfstreamframe","title":"RdfStreamFrame","text":"<p>RDF stream frame \u2013 base message for RDF streams.</p> Field Type Label Description rows RdfStreamRow repeated Stream rows <p></p>"},{"location":"specification/reference/#rdfstreamoptions","title":"RdfStreamOptions","text":"<p>RDF stream options</p> Field Type Label Description stream_name string Name of the stream (completely optional). This may be used for, e.g., topic names in a pub/sub system. physical_type PhysicalStreamType Type of the stream (required) generalized_statements bool Whether the stream may contain generalized triples, quads, or datasets rdf_star bool Whether the stream may contain RDF-star statements max_name_table_size uint32 Maximum size of the name lookup table max_prefix_table_size uint32 Maximum size of the prefix lookup table max_datatype_table_size uint32 Maximum size of the datatype lookup table logical_type LogicalStreamType Logical (RDF-STaX-based) stream type In contrast to the physical type, this field is entirely optional. version uint32 Protocol version (required) For Jelly 1.0.x value must be 1. For custom extensions, the value must be 10000 or higher. <p></p>"},{"location":"specification/reference/#rdfstreamrow","title":"RdfStreamRow","text":"<p>RDF stream row</p> Field Type Label Description options RdfStreamOptions Stream options. Must occur at the start of the stream. triple RdfTriple RDF triple statement. Valid in streams of physical type TRIPLES or GRAPHS. quad RdfQuad RDF quad statement. Only valid in streams of physical type QUADS. graph_start RdfGraphStart Graph boundary: ends the currently transmitted graph and starts a new one Only valid in streams of physical type GRAPHS. graph_end RdfGraphEnd Explicit end of a graph. Signals the consumer that the transmitted graph is complete. Only valid in streams of physical type GRAPHS. name RdfNameEntry Entry in the name lookup table. prefix RdfPrefixEntry Entry in the prefix lookup table. datatype RdfDatatypeEntry Entry in the datatype lookup table. <p></p>"},{"location":"specification/reference/#rdftriple","title":"RdfTriple","text":"<p>RDF triple</p> <p>For each term (subject, predicate, object), the fields are repeated for performance reasons. This is to avoid the need for boxing each term in a separate message.</p> <p>Note: this message allows for representing generalized RDF triples (for example, with literals as predicates). Whether this is used in the stream is determined by the stream options (see RdfStreamOptions).</p> <p>If no field in a given oneof is set, the term is interpreted as a repeated term \u2013 the same as the term in the same position in the previous triple. In the first triple of the stream, all terms must be set. All terms must also be set in quoted triples (RDF-star).</p> Field Type Label Description s_iri RdfIri IRI s_bnode string Blank node s_literal RdfLiteral Literal Only valid in a generalized RDF stream. s_triple_term RdfTriple RDF-star quoted triple p_iri RdfIri IRI p_bnode string Blank node Only valid in a generalized RDF stream. p_literal RdfLiteral Literal Only valid in a generalized RDF stream. p_triple_term RdfTriple RDF-star quoted triple o_iri RdfIri IRI o_bnode string Blank node o_literal RdfLiteral Literal o_triple_term RdfTriple RDF-star quoted triple <p></p>"},{"location":"specification/reference/#logicalstreamtype","title":"LogicalStreamType","text":"<p>Logical stream type, according to the RDF Stream Taxonomy (RDF-STaX). Type 0 is reserved for the unspecified stream type. The rest of the type numbers follow the taxonomical structure of RDF-STaX. For example: 1 is a subtype of 0, 13 and 23 are subtypes of 3,  114 is a subtype of 14, etc.</p> <p>Types 1\u20134 correspond to the four base concrete stream types. Their  subtypes can be in most cases simply processed in the same way as  the base types. Therefore, implementations can take the modulo 10 of the stream  type to determine the base type of the stream and use this information  to select the appropriate processing logic.</p> <p>RDF-STaX version: 1.1.2 https://w3id.org/stax/1.1.2</p> <p>^ The above URL is used to automatically determine the version of RDF-STaX in the Jelly protocol specification. Please keep it up-to-date and in the same format.</p> Name Number Description LOGICAL_STREAM_TYPE_UNSPECIFIED 0 Unspecified stream type \u2013 invalid LOGICAL_STREAM_TYPE_FLAT_TRIPLES 1 Flat RDF triple stream https://w3id.org/stax/ontology#flatTripleStream LOGICAL_STREAM_TYPE_FLAT_QUADS 2 Flat RDF quad stream https://w3id.org/stax/ontology#flatQuadStream LOGICAL_STREAM_TYPE_GRAPHS 3 RDF graph stream https://w3id.org/stax/ontology#graphStream LOGICAL_STREAM_TYPE_DATASETS 4 RDF dataset stream https://w3id.org/stax/ontology#datasetStream LOGICAL_STREAM_TYPE_SUBJECT_GRAPHS 13 RDF subject graph stream (subtype of RDF graph stream) https://w3id.org/stax/ontology#subjectGraphStream LOGICAL_STREAM_TYPE_NAMED_GRAPHS 14 RDF named graph stream (subtype of RDF dataset stream) https://w3id.org/stax/ontology#namedGraphStream LOGICAL_STREAM_TYPE_TIMESTAMPED_NAMED_GRAPHS 114 RDF timestamped named graph stream (subtype of RDF dataset stream) https://w3id.org/stax/ontology#timestampedNamedGraphStream <p></p>"},{"location":"specification/reference/#physicalstreamtype","title":"PhysicalStreamType","text":"<p>Physical stream type This determines how the data is encoded in the stream, not the logical structure of the data. See LogicalStreamType for the latter.</p> Name Number Description PHYSICAL_STREAM_TYPE_UNSPECIFIED 0 Unspecified stream type \u2013 invalid PHYSICAL_STREAM_TYPE_TRIPLES 1 RDF triples PHYSICAL_STREAM_TYPE_QUADS 2 RDF quads PHYSICAL_STREAM_TYPE_GRAPHS 3 RDF triples grouped in graphs"},{"location":"specification/reference/#scalar-value-types","title":"Scalar Value Types","text":".proto Type Notes C++ Java Python Go C# PHP Ruby  double double double float float64 double float Float  float float float float float32 float float Float  int32 Uses variable-length encoding. Inefficient for encoding negative numbers \u2013 if your field is likely to have negative values, use sint32 instead. int32 int int int32 int integer Bignum or Fixnum (as required)  int64 Uses variable-length encoding. Inefficient for encoding negative numbers \u2013 if your field is likely to have negative values, use sint64 instead. int64 long int/long int64 long integer/string Bignum  uint32 Uses variable-length encoding. uint32 int int/long uint32 uint integer Bignum or Fixnum (as required)  uint64 Uses variable-length encoding. uint64 long int/long uint64 ulong integer/string Bignum or Fixnum (as required)  sint32 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int32s. int32 int int int32 int integer Bignum or Fixnum (as required)  sint64 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int64s. int64 long int/long int64 long integer/string Bignum  fixed32 Always four bytes. More efficient than uint32 if values are often greater than 2^28. uint32 int int uint32 uint integer Bignum or Fixnum (as required)  fixed64 Always eight bytes. More efficient than uint64 if values are often greater than 2^56. uint64 long int/long uint64 ulong integer/string Bignum  sfixed32 Always four bytes. int32 int int int32 int integer Bignum or Fixnum (as required)  sfixed64 Always eight bytes. int64 long int/long int64 long integer/string Bignum  bool bool boolean boolean bool bool boolean TrueClass/FalseClass  string A string must always contain UTF-8 encoded or 7-bit ASCII text. string String str/unicode string string string String (UTF-8)  bytes May contain any arbitrary sequence of bytes. string ByteString str []byte ByteString string String (ASCII-8BIT)"},{"location":"specification/serialization/","title":"Jelly serialization format specification","text":"<p>This document is the specification of the Jelly serialization format. It is intended for implementers of Jelly libraries and applications. If you are looking for a user-friendly introduction to Jelly, see the Jelly index page.</p> <p>This document is accompanied by the Jelly Protobuf reference and the Protobuf definition itself (<code>rdf.proto</code>).</p> <p>The following assumptions are used in this document:</p> <ul> <li>The basis for the terms used is the RDF 1.1 specification (W3C Recommendation 25 February 2014).</li> <li>In parts referring to RDF-star, the RDF-star draft specification (W3C Community Group Draft Report 29 June 2023) is used. As the scope in which the RDF-star specification is used here is minimal, later versions of the specification are expected to be compatible with this document.</li> <li>In parts referring to the RDF Stream Taxonomy (RDF-STaX), the RDF-STaX version 1.1.2 ontology and taxonomy are used.</li> <li>All strings in the serialization are assumed to be UTF-8 encoded.</li> </ul> Document information Author: Piotr Sowi\u0144ski (Ostrzyciel) Version: 1.0.0 Date: August 24, 2024 Permanent URL: <code>https://w3id.org/jelly/1.0.0/specification/serialization</code> Document status: Stable specification <p>Info</p> <p>The key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\",  \"MAY\", and \"OPTIONAL\" in this document are to be interpreted as described in RFC 2119.</p> <p>Note</p> <p>The \"Note\" blocks in this document are not part of the specification, but rather provide additional information for implementers.</p> <p>Note</p> <p>The \"Example\" blocks in this document are not part of the specification, but rather provide informal examples of the serialization format.</p>"},{"location":"specification/serialization/#conformance","title":"Conformance","text":"<p>Implementations MAY choose to implement only a subset of the following specification. In this case, they SHOULD clearly specify which parts of the specification they implement. In the rest of this specification, the keywords \"MUST\", \"MUST NOT\", etc. refer to full (not partial) implementations.</p> <p>Note</p> <p>Implementations may in particular choose to not implement features that are not supported on the target platform (e.g., RDF datasets, RDF-star, generalized RDF terms, etc.).</p> <p>Implementations MAY also choose to extend Jelly with additional features that SHOULD NOT interfere with the serialization being readable by implementations which follow the specification.</p>"},{"location":"specification/serialization/#versioning","title":"Versioning","text":"<p>The protocol follows the Semantic Versioning 2.0 scheme. Each MAJOR.MINOR semantic version corresponds to an integer version tag in the protocol. The version tag is encoded in the <code>version</code> field of the <code>RdfStreamOptions</code> message. See also the section on stream options for more information on how to handle the version tags in serialized streams.</p> <p>The following versions of the protocol are defined:</p> Version tag Semantic version 1 1.0.x (current) <p>Note</p> <p>Releases of the protocol are published on GitHub.</p>"},{"location":"specification/serialization/#backward-compatibility","title":"Backward compatibility","text":"<p>Implementations SHOULD ensure backward compatibility. To achieve backward compatibility, the implementation MUST be able to read all messages from the previous releases of the protocol with the same MAJOR version. The implementation MAY also be able to read messages from previous releases of the protocol with a different MAJOR version.</p> <p>Note</p> <p>The protocol is designed in such a way that you don't need to worry about backward compatibility. The only thing you need to do is to implement the latest version of the protocol, and you will automatically get backward compatibility with all previous versions (of the same MAJOR).</p>"},{"location":"specification/serialization/#forward-compatibility","title":"Forward compatibility","text":"<p>Forward compatibility is not guaranteed. Implementations MAY be able to read messages from future releases of the protocol with the same MAJOR version. Implementations MAY also be able to read messages from future releases of the protocol with a different MAJOR version.</p>"},{"location":"specification/serialization/#actors-and-implementations","title":"Actors and implementations","text":"<p>Jelly assumes there to be two actors involved in processing the stream: the producer (serializer) and the consumer (parser). The producer is responsible for serializing the RDF data into the Jelly format, and the consumer is responsible for parsing the Jelly format into RDF data.</p> <p>Implementations may include only the producer, only the consumer, or both.</p>"},{"location":"specification/serialization/#format-specification","title":"Format specification","text":"<p>The Jelly serialization format uses Protocol Buffers version 3 as the underlying serialization format. All implementations MUST use a compliant Protocol Buffers implementation. The Protocol Buffers schema for Jelly serialization is defined in <code>rdf.proto</code> (source code, reference).</p> <p>The Jelly format is a stream (i.e., an ordered sequence) of stream frames. The frames may be sent one-by-one using a dedicated streaming protocol (e.g., gRPC, MQTT, Kafka) or written in sequence to a byte stream (e.g., a file or socket). When writing to a byte stream, the frames MUST be delimeted \u2013 see the delimited variant.</p> <p>Jelly supports several distinct physical types of streams, and uses a simple and configurable compression mechanism using lookup tables.</p>"},{"location":"specification/serialization/#stream-frames","title":"Stream frames","text":"<p>A stream frame is a message of type <code>RdfStreamFrame</code> (reference). The message has only one field (<code>rows</code>), which is a repeated field of type <code>RdfStreamRow</code> (reference). A stream frame may contain any number of rows, however it is RECOMMENDED to keep the size of the frames below 1 MB. The semantics for the frames are not defined by the protocol. The end users are free to define their own semantics for the frames.</p> <p>Note</p> <p>A stream frame in \"simple flat file\" is just a batch of RDF statements \u2013 the stream frames may carry no semantics in this case. You can make the stream frame as long as the file itself, but this is not recommended, as it would make the file harder to process.</p> <p>Note</p> <p>Stream frames can also be used to indicate individual stream elements. For example, in the case of a stream of RDF datasets, each frame may contain one dataset. RiverBench datasets use this convention in their distributions.</p>"},{"location":"specification/serialization/#ordering","title":"Ordering","text":"<p>Stream frames MUST be processed strictly in order to preserve the semantics of the stream. Each stream frame MUST be processed in its entirety before the next stream frame is processed.</p> <p>Implementations MAY choose to adopt a non-standard solution where the order or delivery of the frames is not guaranteed and the stream can be read in more than one order or without some frames. The implementation MUST clearly specify in the documentation that it uses such a non-standard solution.</p> <p>Note</p> <p>An example where not adhering to the strict ordering may be useful is when you are dealing with a network streaming protocol that does not guarantee the order of the messages (e.g., MQTT).</p> <p>Note</p> <p>The main thing you will need to worry about is the order of the lookup tables. If you can, emit all lookup tables at the beginning of the stream. When using stream partitions (e.g., in Kafka), you should ensure that the lookups are emitted to each partition. Alternatively, you can transmit the lookup tables separately from the stream.</p>"},{"location":"specification/serialization/#stream-rows","title":"Stream rows","text":"<p>A stream row is a message of type <code>RdfStreamRow</code>. It has one of the following fields set:</p> <ul> <li><code>options</code> (1) \u2013 stream options header, indicating the compression options and the used RDF features in the stream.</li> <li><code>triple</code> (2) \u2013 RDF triple statement. It MUST NOT appear in streams of type other than <code>PHYSICAL_STREAM_TYPE_TRIPLES</code> or <code>PHYSICAL_STREAM_TYPE_GRAPHS</code>.</li> <li><code>quad</code> (3) \u2013 RDF quad statement. It MUST NOT appear in streams of type other than <code>PHYSICAL_STREAM_TYPE_QUADS</code>.</li> <li><code>graph_start</code> (4) \u2013 indicates the start of a graph (named or default). It MUST NOT appear in streams of type other than <code>PHYSICAL_STREAM_TYPE_GRAPHS</code>.</li> <li><code>graph_end</code> (5) \u2013 indicates the end of a graph (named or default). It MUST NOT appear in streams of type other than <code>PHYSICAL_STREAM_TYPE_GRAPHS</code>.</li> <li><code>name</code> (9) \u2013 entry in the name lookup.</li> <li><code>prefix</code> (10) \u2013 entry in the prefix lookup.</li> <li><code>datatype</code> (11) \u2013 entry in the datatype lookup.</li> </ul> <p>Stream rows MUST be processed strictly in order to preserve the semantics of the stream.</p>"},{"location":"specification/serialization/#physical-stream-types","title":"Physical stream types","text":"<p>The physical type of the stream MUST be explicitly specified in the stream options header. The physical type of the stream is defined by the <code>PhysicalStreamType</code> enum (reference). The following types are defined:</p> <ul> <li><code>PHYSICAL_STREAM_TYPE_UNSPECIFIED</code> (0) \u2013 default value. This physical stream type MUST NOT be used. The implementations SHOULD treat this value as an error.</li> <li><code>PHYSICAL_STREAM_TYPE_TRIPLES</code> (1) \u2013 stream of RDF triple statements. In this case, the stream MUST NOT contain <code>RdfStreamRow</code> messages with the <code>quad</code>, <code>graph_start</code>, or <code>graph_end</code> fields set.</li> <li><code>PHYSICAL_STREAM_TYPE_QUADS</code> (2) \u2013 stream of RDF quad statements (same as simple statements in N-Quads). In this case, the stream MUST NOT contain <code>RdfStreamRow</code> messages with the <code>triple</code>, <code>graph_start</code>, or <code>graph_end</code> fields set.</li> <li><code>PHYSICAL_STREAM_TYPE_GRAPHS</code> (3) \u2013 stream of RDF graphs (named or default). In this case, the stream MUST NOT contain <code>RdfStreamRow</code> messages with the <code>quad</code> fields set.</li> </ul> <p>Note</p> <p>See also a more human explanation of the available physical stream types.</p> <p>Note</p> <p>The physical stream type only specifies how the data is encoded, not how it should be interpreted. See the logical stream types for a mechanism to specify the semantics of the stream.</p>"},{"location":"specification/serialization/#logical-stream-types","title":"Logical stream types","text":"<p>Specifying the logical stream type in the stream options header is OPTIONAL. When it is specified, the implementations MAY use it to determine the semantics of the stream. The implementations also MAY ignore the specified logical stream type and interpret the stream in any other manner. The logical stream type is defined by the <code>LogicalStreamType</code> enum (reference).</p> <p>This version of Jelly uses the RDF Stream Taxonomy (RDF-STaX) 1.1.2 and implements all stream types of RDF-STaX as logical stream types. The following logical stream types are defined:</p> <ul> <li><code>LOGICAL_STREAM_TYPE_UNSPECIFIED</code> (0) \u2013 default value. This logical stream type is used when the serializer chooses not to specify the logical stream type.</li> <li><code>LOGICAL_STREAM_TYPE_FLAT_TRIPLES</code> (1)<ul> <li>RDF-STaX name: Flat RDF triple stream</li> <li>RDF-STaX IRI: <code>https://w3id.org/stax/ontology#flatTripleStream</code></li> </ul> </li> <li><code>LOGICAL_STREAM_TYPE_FLAT_QUADS</code> (2)<ul> <li>RDF-STaX name: Flat RDF quad stream</li> <li>RDF-STaX IRI: <code>https://w3id.org/stax/ontology#flatQuadStream</code></li> </ul> </li> <li><code>LOGICAL_STREAM_TYPE_GRAPHS</code> (3)<ul> <li>RDF-STaX name: RDF graph stream</li> <li>RDF-STaX IRI: <code>https://w3id.org/stax/ontology#graphStream</code></li> </ul> </li> <li><code>LOGICAL_STREAM_TYPE_DATASETS</code> (4)<ul> <li>RDF-STaX name: RDF dataset stream</li> <li>RDF-STaX IRI: <code>https://w3id.org/stax/ontology#datasetStream</code></li> </ul> </li> <li><code>LOGICAL_STREAM_TYPE_SUBJECT_GRAPHS</code> (13)<ul> <li>RDF-STaX name: RDF subject graph stream</li> <li>RDF-STaX IRI: <code>https://w3id.org/stax/ontology#subjectGraphStream</code></li> <li>Subtype of: <code>LOGICAL_STREAM_TYPE_GRAPHS</code> (3)</li> </ul> </li> <li><code>LOGICAL_STREAM_TYPE_NAMED_GRAPHS</code> (14)<ul> <li>RDF-STaX name: RDF named graph stream</li> <li>RDF-STaX IRI: <code>https://w3id.org/stax/ontology#namedGraphStream</code></li> <li>Subtype of: <code>LOGICAL_STREAM_TYPE_DATASETS</code> (4)</li> </ul> </li> <li><code>LOGICAL_STREAM_TYPE_TIMESTAMPED_NAMED_GRAPHS</code> (114)<ul> <li>RDF-STaX name: Timestamped RDF named graph stream</li> <li>RDF-STaX IRI: <code>https://w3id.org/stax/ontology#timestampedNamedGraphStream</code></li> <li>Subtype of: <code>LOGICAL_STREAM_TYPE_NAMED_GRAPHS</code> (14)</li> </ul> </li> </ul>"},{"location":"specification/serialization/#version-compatibility-and-base-types","title":"Version compatibility and base types","text":"<p>In all Jelly versions 1.x.y there MUST be the same four base logical stream types (numbered 1, 2, 3, 4). The remaining logical stream types (with numbers greater than 10) may change between releases in the 1.x.y family, following the versioning rules. The four base types (1\u20134) are thus fixed, enabling forward compatibility for implementations that only support the base types.</p> <p>Each remaining logical stream type is a subtype of a base type (including recursive subtyping). To determine the base type of a logical stream type, the implementation MUST take the last digit of the logical stream type number, which is equivalent to the modulo 10 operation. Implementations MAY choose to treat a subtype of a base type in the same manner as the base type itself.</p> Example (click to expand) <p>The base type of <code>LOGICAL_STREAM_TYPE_NAMED_GRAPHS</code> (14) is <code>LOGICAL_STREAM_TYPE_DATASETS</code> (4).</p> <p>The base type of <code>LOGICAL_STREAM_TYPE_TIMESTAMPED_NAMED_GRAPHS</code> (114) is <code>LOGICAL_STREAM_TYPE_DATASETS</code> (4).</p> <p>The base type of <code>LOGICAL_STREAM_TYPE_FLAT_TRIPLES</code> (1) is <code>LOGICAL_STREAM_TYPE_FLAT_TRIPLES</code> (1).</p> <p>Note</p> <p>In practice, the base logical stream types (1\u20134) are the most important part, determining how the data should be shaped and processed. The other logical stream types are used to provide additional information about the stream. If you are implementing a streaming serializer/deserializer, you should focus on the base types and treat their subtypes in the same way. So, do a modulo 10 on the stream type and you are good to go.</p>"},{"location":"specification/serialization/#consistency-with-physical-stream-types","title":"Consistency with physical stream types","text":"<p>Implementations MAY choose to use the logical stream type to determine how to interpret the stream. In that case, the implementation SHOULD ensure that the logical stream type is consistent with the physical stream type in the sense that the implementation supports this combination of stream types. If the logical stream type is inconsistent with the physical stream type, the implementation MAY throw an error.</p> <p>The following table shows the RECOMMENDED support matrix for the logical stream types and physical stream types, along with the RECOMMENDED manner in which the stream should be interpreted:</p> RDF-STaX (logical type) / Physical type <code>TRIPLES</code> <code>QUADS</code> <code>GRAPHS</code> <code>LOGICAL_STREAM_TYPE_GRAPHS</code> Framed \u2718 \u2718 <code>LOGICAL_STREAM_TYPE_SUBJECT_GRAPHS</code> Framed \u2718 \u2718 <code>LOGICAL_STREAM_TYPE_DATASETS</code> \u2718 Framed Framed <code>LOGICAL_STREAM_TYPE_NAMED_GRAPHS</code> \u2718 Framed Framed <code>LOGICAL_STREAM_TYPE_TIMESTAMPED_NAMED_GRAPHS</code> \u2718 Framed Framed <code>LOGICAL_STREAM_TYPE_FLAT_TRIPLES</code> Continuous \u2718 \u2718 <code>LOGICAL_STREAM_TYPE_FLAT_QUADS</code> \u2718 Continuous Continuous <p>In the table above, the following interpretations are used:</p> <ul> <li>Framed \u2013 each stream frame SHOULD be interpreted as a stream element, as per RDF-STaX definition.</li> <li>Continuous \u2013 the stream SHOULD be interpreted as a continuous flat stream of elements, as per RDF-STaX definition. In this case, the stream frames carry no meaning.</li> <li>\u2718 \u2013 the combination of the logical stream type and the physical stream type is not directly supported.</li> </ul> <p>The implementations MAY choose to interpret the stream in a different manner than the one specified in the table.</p> <p>Note</p> <p>See the user's guide for a more intuitive explanation of what this means.</p> <p>In any case, you can choose to entirely ignore this table which should only be treated as a recommended starting point. For example, you could have an RDF graph stream with physical type <code>GRAPHS</code>, where each graph spans multiple stream frames. This and other non-standard combinations are completely fine, just make sure that all actors involved support it.</p>"},{"location":"specification/serialization/#stream-options","title":"Stream options","text":"<p>The stream options is a message of type <code>RdfStreamOptions</code> (reference). It MUST be the first row in the stream. It MAY appear more than once in the stream (also after other rows), but it MUST be identical to all previous occurrences. Implementations MAY throw an error if the stream options header is not present at the start of the stream, alternatively, they MAY use the default options. Implementations SHOULD NOT throw an error if the stream options header is present more than once in the stream.</p> <p>The stream options header instructs the consumer of the stream (parser) on the size of the needed lookups to decode the stream and the features used by the stream.</p> <p>The stream options header contains the following fields:</p> <ul> <li><code>stream_name</code> (1) \u2013 name of the stream. This field is OPTIONAL and the manner in which it should be used is not defined by this specification. It MAY be used to identify the stream.</li> <li><code>physical_type</code> (2) \u2013 physical type of the stream. This field is REQUIRED.</li> <li><code>generalized_statements</code> (3) \u2013 whether the stream contains generalized RDF triples or graphs. This field MUST be set to true if the stream contains generalized RDF triples or graphs. It SHOULD NOT be set to true if the stream does not use this feature. This field is OPTIONAL and defaults to false.</li> <li><code>rdf_star</code> (4) \u2013 whether the stream uses RDF-star (quoted triples). This field MUST be set to true if the stream uses RDF-star. It SHOULD NOT be set to true if the stream does not use this feature. This field is OPTIONAL and defaults to false.</li> <li><code>max_name_table_size</code> (9) \u2013 maximum size of the name lookup. This field is OPTIONAL and defaults to 0 (no lookup). If the field is set to 0, the name lookup MUST NOT be used in the stream. If the field is set to a positive value, the name lookup SHOULD be used in the stream and the size of the lookup MUST NOT exceed the value of this field.</li> <li><code>max_prefix_table_size</code> (10) \u2013 maximum size of the prefix lookup. This field is OPTIONAL and defaults to 0 (no lookup). If the field is set to 0, the prefix lookup MUST NOT be used in the stream. If the field is set to a positive value, the prefix lookup SHOULD be used in the stream and the size of the lookup MUST NOT exceed the value of this field.</li> <li><code>max_datatype_table_size</code> (11) \u2013 maximum size of the datatype lookup. This field is OPTIONAL and defaults to 0 (no lookup). If the field is set to 0, the datatype lookup MUST NOT be used in the stream (which effectively prohibits the use of datatype literals). If the field is set to a positive value, the datatype lookup SHOULD be used in the stream and the size of the lookup MUST NOT exceed the value of this field.</li> <li><code>logical_type</code> (14) \u2013 logical type of the stream, based on RDF-STaX. This field is OPTIONAL and defaults to <code>LOGICAL_STREAM_TYPE_UNSPECIFIED</code>.</li> <li><code>version</code> (15) \u2013 version tag of the stream. This field is REQUIRED.<ul> <li>The version tag is encoded as a varint. The version tag MUST be greater than 0.</li> <li>The producer of the stream MUST set the version tag to the version tag of the implementation.</li> <li>The consumer SHOULD throw an error if the version tag is greater than the version tag of the implementation.</li> <li>The consumer SHOULD throw an error if the version tag is zero.</li> <li>The consumer SHOULD NOT throw an error if the version tag is not zero but lower than the version tag of the implementation.</li> <li>The producer may use version tags greater than 10000 to indicate non-standard versions of the protocol.</li> </ul> </li> </ul>"},{"location":"specification/serialization/#prefix-name-and-datatype-lookup-entries","title":"Prefix, name, and datatype lookup entries","text":"<p>Jelly uses a common mechanism of lookup tables for IRI prefixes, IRI names (postfixes), and datatypes. The lookups are used to compress the IRIs and datatypes in the stream. All lookups share the same base mechanism:</p> <ul> <li>The lookup is a map from a varint to a valid UTF-8 string.</li> <li>The lookup can be modified at any point in the stream. The modification consists of setting the lookup for a given varint to a given string. The modification MUST be applied to all subsequent rows in the stream.</li> <li>The first use of a given lookup element MUST be after it is defined in the lookup. If the consumer encounters a lookup element that is not defined in the lookup, it SHOULD throw an error.</li> <li>The lookups are indexed from <code>1</code>. The default value of <code>0</code> is a special value:<ul> <li>If the index is set to <code>0</code> in the first entry of the lookup in the stream, it MUST be interpreted as the value <code>1</code>.</li> <li>If the index is set to <code>0</code> in any other lookup entry, it MUST be interpreted as <code>previous_index + 1</code>, that is, the index of the previous entry incremented by one.</li> </ul> </li> <li>The maximum size of the lookup is communicated at the start of the stream (see stream options header). The producer of the stream MUST NOT exceed the maximum size of the lookup. The consumer of the stream MAY implement the lookup as a fixed-size array, or extend it dynamically.</li> <li>The lookup is updated with different messages, depending on the type of the lookup:<ul> <li><code>RdfNameEntry</code> for the name lookup,</li> <li><code>RdfPrefixEntry</code> for the prefix lookup,</li> <li><code>RdfDatatypeEntry</code> for the datatype lookup.</li> </ul> </li> <li>The producer may use any strategy to update the lookup.</li> </ul> <p>Note</p> <p>The spec does not specify what strategy should the producer use to update the lookup. You can use a the LRU strategy (as used in the Scala implementation), LFU, or something more complex. You can also have a fixed lookup in the producer and communicate it at the start of the stream. This is possible if you are using a fixed set of prefixes, names, or datatypes and want to conserve computing power (e.g., in IoT devices).</p> <p>The simplest way to implement the consumer's lookup is to just use an indexed array of fixed size. The workload on the consumer's side is much lower than on the producer's side, so your choice of the strategy depends largely on the producer.</p> <p>Note</p> <p>The default value of <code>0</code> has a special meaning in lookup entries. You should take advantage of that and use it whenever possible. As the value of <code>0</code> is encoded with exactly zero bytes, you can save some space by using it.</p>"},{"location":"specification/serialization/#rdf-statements-and-graphs","title":"RDF statements and graphs","text":"<p>RDF statements (triples or quads) are communicated in three different ways, depending on the type of the stream:</p> <ul> <li><code>PHYSICAL_STREAM_TYPE_TRIPLES</code> \u2013 triples are encoded using <code>RdfTriple</code> messages.<ul> <li><code>RdfTriple</code> consists of three oneofs: <code>subject</code>, <code>predicate</code>, <code>object</code>, corresponding to the three terms in an RDF triple. Each of these oneofs has four fields, out of which at most one MUST be set.</li> <li>If no field in a given oneof is set, the term is considered to be a repeated term (see repeated terms).</li> </ul> </li> <li><code>PHYSICAL_STREAM_TYPE_QUADS</code> \u2013 quads are encoded using <code>RdfQuad</code> messages.<ul> <li><code>RdfQuad</code> consists of four oneofs: <code>subject</code>, <code>predicate</code>, <code>object</code>, <code>graph</code>, corresponding to the three terms and one graph node of the quad. Each of these oneofs has four fields, out of which at most one MUST be set.</li> <li>If no field in a given oneof is set, the term is considered to be a repeated term/graph node (see repeated terms).</li> </ul> </li> <li><code>PHYSICAL_STREAM_TYPE_GRAPHS</code> \u2013 graphs are encoded using <code>RdfGraphStart</code> and <code>RdfGraphEnd</code> messages. Triples between the start and end of the graph are encoded using <code>RdfTriple</code> messages. If a triple is between the start and end of the graph, it is considered to be in the graph.<ul> <li>In this type of stream, triples MUST NOT occur outside of a graph. If a triple is encountered outside a graph, the consumer SHOULD throw an error.</li> <li>A graph start MUST NOT occur inside another graph. If a graph start is encountered inside another graph, the consumer SHOULD throw an error.</li> <li>A graph end MUST NOT occur outside a graph. If a graph end is encountered outside a graph, the consumer MAY throw an error.</li> <li>A graph MAY be empty (i.e., it may contain no triples).</li> <li>A graph corresponding to one graph node MAY occur multiple times in a stream or a stream frame. The consumer MUST treat all occurrences of the graph as a single RDF graph.</li> <li>A graph MAY span more than one stream frame. The consumer MUST treat the graph spanning several stream frames as a single RDF graph.</li> <li>Exactly one field in the <code>RdfGraphStart</code> message MUST be set \u2013 no repeated terms are allowed here. The consumer SHOULD throw an error if no field in the <code>graph</code> oneof is set.</li> </ul> </li> </ul> <p>Note</p> <p>If the stream is meant to represent a single RDF dataset, then the graphs should be able to stretch across several stream frames. If the stream is meant to represent a stream of RDF datasets, then the graphs should be contained within a single stream frame.</p>"},{"location":"specification/serialization/#repeated-terms","title":"Repeated terms","text":"<p>Both <code>RdfTriple</code> and <code>RdfQuad</code> offer a simple compression mechanism \u2013 repeated terms. If a term in a given position (subject, predicate, object, or graph node in quads) is not set, then it is interpreted to be the same as the term in the same position in the previous triple or quad. Repeated terms are encoded simply by not setting any field in the corresponding oneof, and therefore take up zero bytes in the stream.</p> <ul> <li>Repeated terms MUST NOT occur in quoted triples.</li> <li>Repeated terms MUST NOT occur in the first statement row of the stream.</li> <li>Repeated terms MAY occur in the first statement row of a stream frame. In this case, the repeated terms MUST be interpreted as repeated from the previous stream frame.</li> <li>A repeated term in a given position MAY occur after a repeated term. The consumer MUST interpret all consecutive appearances of the repeated term as the same term.</li> </ul> Example (click to expand) <p>In the example the wrapping <code>RdfStreamRow</code>s were omitted for brevity:</p> <pre><code># First row\nRdfTriple {\n    s_iri: RdfIri {\n        prefix_id: 1\n        name_id: 1\n    }\n    p_iri: RdfIri {\n        prefix_id: 1\n        name_id: 2\n    }\n    o_bnode: \"b1\"\n}\n\n# Second row \u2013 repeating the subject and predicate\n# s_iri and p_iri are reused from the previous row\nRdfTriple {\n    o_bnode: \"b2\"\n}\n\n# Third row \u2013 repeating the subject and object\n# s_iri and o_bnode are reused from the first row\nRdfTriple {\n    p_iri: RdfIri {\n        prefix_id: 2\n        name_id: 3\n    }\n}\n</code></pre> <p>Note</p> <p>Repeated terms are a simple, yet incredibly effective compression mechanism and you should use them whenever possible. They are doubly effective: not only you save space by not repeating the terms, but also repeated terms are not encoded at all (zero bytes on the wire), which saves even more space.</p> <p>Note</p> <p>Repeated terms can be simply implemented with four variables (s, p, o, g) holding the last non-repeated value of a term in that position. This O(1) solution is what the Scala implementation uses.</p> <p>Note</p> <p>Although repeated terms can stretch across stream frame boundaries (i.e., refer to values last seen in the previous stream frame), you don't have to use this feature. If your use case requires the stream frames to be more independent of each other (see: stream frame ordering), you can just reset the repeated terms at the start of each stream frame.</p>"},{"location":"specification/serialization/#rdf-terms-and-graph-nodes","title":"RDF terms and graph nodes","text":"<p>RDF terms and graph nodes are encoded using oneofs in <code>RdfTriple</code>, <code>RdfQuad</code>, and <code>RdfGraphStart</code>. The oneofs have each several fields, depending on the type of the term: <code>*_iri</code>, <code>*_bnode</code>, <code>*_literal</code>, <code>*_triple_term</code>, <code>g_default_graph</code>, corresponding to RDF IRIs, blank nodes, literals, RDF-star quoted triples, and the default RDF graph in an RDF dataset, respectively. At most one field in each oneof MUST be set.</p>"},{"location":"specification/serialization/#iris","title":"IRIs","text":"<p>The IRIs are encoded using the <code>RdfIri</code> message. The message has two fields that together make up the IRI:</p> <ul> <li><code>prefix_id</code> (1) \u2013 1-based index of the prefix of the IRI, corresponding to an entry in the prefix lookup.<ul> <li>The default value of <code>0</code> MUST be interpreted as the same value as in the last explictly specified (non-zero) prefix identifier.</li> <li>If <code>0</code> appears in the first IRI of the stream (and in any subsequent IRI), this MUST be interpreted as an empty prefix (zero-length string). This is for example used when the prefix lookup table is set to size zero.</li> </ul> </li> <li><code>name_id</code> (2) \u2013 1-based index of the name (suffix) of the IRI, corresponding to an entry in the name lookup. This field is OPTIONAL and the default value (0) indicates an empty name.<ul> <li>The default value of <code>0</code> MUST be interpreted as <code>previous_name_id + 1</code>, that is, the <code>name_id</code> of the previous IRI incremented by one.</li> <li>If <code>0</code> appears in the first IRI of the stream it MUST be interpreted as <code>1</code>.</li> <li>Multiple <code>0</code> values in a row may occur, in which case the <code>name_id</code> MUST be interpreted as incrementing by one for each <code>0</code> value.</li> </ul> </li> </ul> <p>For the default value behavior to work correctly, IRIs in the stream MUST be processed strictly in order: firstly by stream row, then by term (subject, predicate, object, graph). This also applies recursively to RDF-star quoted triples.</p> <p>The IRI is then constructed by first decoding the prefix and the name using the prefix and name lookup tables, and then concatenating the prefix and the name. The IRI SHOULD be a valid IRI, as defined in RFC 3987.</p> Example with the prefix table (click to expand) <p>Assume the following lookup entries were defined in the stream (wrapping <code>RdfStreamRow</code>s were omitted for brevity):</p> <pre><code>RdfPrefixEntry {\n    id: 0 # default value, interpreted as 1\n    prefix: \"http://example.com/\"\n}\nRdfNameEntry {\n    id: 0 # default value, interpreted as 1\n    name: \"example\"\n}\nRdfNameEntry {\n    id: 0 # default value, interpreted as 1 + 1 = 2\n    name: \"\"\n}\nRdfNameEntry {\n    id: 0 # default value, interpreted as 2 + 1 = 3\n    name: \"test\"\n}\n</code></pre> <p>Then the following IRIs are encoded as follows:</p> <pre><code># http://example.com/example\nRdfIri {\n    prefix_id: 1\n    name_id: 0 # default value, interpreted as 1\n} \n\n# http://example.com/\nRdfIri {\n    prefix_id: 0 # default value, interpreted as 1\n    name_id: 0 # default value, interpreted as 1 + 1 = 2\n}\n\n# http://test.com/test\nRdfIri {\n    prefix_id: 0 # default value, interpreted as 1\n    name_id: 0 # default value, interpreted as 2 + 1 = 3\n}\n</code></pre> <p>Note that the default values (zeroes) are not encoded at all in Protobuf and therefore take up zero bytes in the stream.</p> Example without the prefix table (click to expand) <p>In this example, the prefix lookup table is not used. The lookup entries are defined as follows:</p> <pre><code>RdfNameEntry {\n    id: 0 # default value, interpreted as 1\n    name: \"http://example.com/example\"\n}\n\nRdfNameEntry {\n    id: 0 # default value, interpreted as 1 + 1 = 2\n    name: \"http://example.com/test\"\n}\n</code></pre> <p>Then the following IRIs are encoded as follows:</p> <pre><code># http://example.com/example\nRdfIri {\n    prefix_id: 0 # default value, interpreted as empty prefix\n    name_id: 0 # default value, interpreted as 1\n}\n\n# http://example.com/test\nRdfIri {\n    prefix_id: 0 # default value, interpreted as empty prefix\n    name_id: 0 # default value, interpreted as 1 + 1 = 2\n}\n</code></pre> <p>Note</p> <p>The spec does not specify how to split the IRIs into names and prefixes. You can use any strategy you want, as long as you follow the rules above. The simplest way is to split the IRI at the last occurrence of the <code>#</code> or <code>/</code> character \u2013 this is what the Scala implementation uses. The prefixes are not meant to be user-facing, but you can also use user-defined prefixes (e.g., <code>@prefix</code> in Turtle) to split the IRIs.</p> <p>Note</p> <p>The behavior of the default values is designed to save space in the stream. Usually in RDF many IRIs share the same prefix, so you can save space by not repeating the prefix in the stream. At the same time the name part of the IRI is often unique, so for each name you will need a new entry in the lookup table \u2013 which is often the next entry after the one you have just created.</p>"},{"location":"specification/serialization/#blank-nodes","title":"Blank nodes","text":"<p>RDF blank nodes are represented using simple strings. The string is the identifier of the blank node. The identifier MUST be a valid UTF-8 string.</p> <p>Because the spec does not define the semantics of the stream frames, blank node identifiers are not guaranteed to be unique across multiple stream frames. The consumer MAY choose to treat the blank nodes as unique across the stream (and thus treat all occurences of the identifier as a single node), or it MAY choose to treat them as unique only within a single stream frame. The consumer MAY use the logical stream type to determine how to treat the blank nodes. The producer SHOULD specify in the documentation which strategy it uses.</p> <p>Note</p> <p>If the stream is meant to represent a single RDF graph or dataset (flat RDF stream in RDF-STaX), then the blank node identifiers should be unique across the stream so that you can refer to them across stream frame boundaries. If the frames refer to different graphs or datasets (grouped RDF stream in RDF-STaX), then the blank node identifiers should be unique only within a single frame.</p> <p>Note</p> <p>Many RDF libraries (e.g., RDF4J, Apache Jena) use internal identifiers for blank nodes, which can be used as the identifiers in Jelly streams. You can also use a different format, for example with shorter identifiers to preserve space.</p>"},{"location":"specification/serialization/#literals","title":"Literals","text":"<p>RDF literals are represented using the <code>RdfLiteral</code> message (reference). The message has the following fields:</p> <ul> <li><code>lex</code> (1) \u2013 the lexical form of the literal in UTF-8. This field is OPTIONAL and defaults to an empty string.</li> <li><code>literalKind</code> oneof. At most one of the following fields MUST be set:<ul> <li><code>langtag</code> (2) \u2013 UTF-8 language tag, indicating that the literal is a language-tagged string (has datatype IRI equal to <code>http://www.w3.org/1999/02/22-rdf-syntax-ns#langString</code>). The language tag SHOULD be a valid BCP 47 language tag.</li> <li><code>datatype</code> (3) \u2013 1-based index of the datatype in the datatype lookup, indicating that the literal is a typed literal. The value of this field MUST be greater than 0 and it MUST correspond to a valid entry in the datatype lookup.</li> </ul> </li> </ul> <p>If no field in the <code>literalKind</code> oneof is set, then the literal MUST be interpreted as a simple literal (has datatype IRI equal to <code>http://www.w3.org/2001/XMLSchema#string</code>).</p> <p>Note</p> <p>Using the default value of <code>0</code> for the <code>datatype</code> field is not allowed, in contrast to names and prefixes in RdfIri. This is because the <code>datatype</code> field itself is optional and the default value would be ambiguous.</p>"},{"location":"specification/serialization/#quoted-triples-rdf-star","title":"Quoted triples (RDF-star)","text":"<p>RDF-star quoted triples are represented using the <code>RdfTriple</code> message (reference). Quoted triples are encoded in the same manner as triple statements, with the only difference being that repeated terms MUST NOT be used in quoted triples. The consumer SHOULD throw an error if a repeated term is encountered in a quoted triple.</p> <p>Quoted triples may be nested up to arbitrary depth. The consumer SHOULD throw an error if the depth of the nesting exceeds the capabilities of the implementation.</p>"},{"location":"specification/serialization/#graph-nodes","title":"Graph nodes","text":"<p>Literal, IRI, and blank node values for graph nodes are encoded in the same manner as for the subject, predicate, and object terms.</p> <p>The default graph node is represented using the <code>RdfDefaultGraph</code> message (reference). The message is empty and has no fields. The default graph node indicates that the triple is part of the default graph.</p>"},{"location":"specification/serialization/#delimited-variant-of-jelly","title":"Delimited variant of Jelly","text":"<p>Note</p> <p>By default, Protobuf messages are not delimited, so if you write multiple messages to the same file / socket / byte stream, you need to add some kind of delimiter between them. Jelly uses the convention already implemented in some protobuf libraries of prepending a varint before the message, to specify the length of the message. </p> <p>A byte stream (or file) in the delimited variant MUST consist of a series of delimited <code>RdfStreamFrame</code> messages. A delimited message is a message that has a varint prepended before it, specifying the length of the message in bytes.</p> <p>Implementing the delimited variant is OPTIONAL.</p>"},{"location":"specification/serialization/#delimited-variant-implementations","title":"Delimited variant implementations","text":"<p>The delimiting convention is implemented in Protobuf libraries for:</p> <ul> <li>C++: delimited_message_util.cc</li> <li>Java / Scala: writeDelimitedTo and parseDelimitedFrom</li> </ul> <p>The JVM (Scala) implementation of Jelly also supports the delimited variant \u2013 see the documentation.</p>"},{"location":"specification/serialization/#internet-media-type-and-file-extension","title":"Internet media type and file extension","text":"<p>The RECOMMENDED media type for Jelly is <code>application/x-jelly-rdf</code>. The RECOMMENDED file extension is <code>.jelly</code>.</p> <p>The files SHOULD be saved in the delimited variant of Jelly.</p>"},{"location":"specification/serialization/#implementations","title":"Implementations","text":"<p>This section is not part of the specification.</p> <p>The following implementations of the Jelly serialization format specification are available:</p> <ul> <li>Jelly-JVM (Scala) implementation<ul> <li>Specification version: 1.0.0</li> <li>Implemented actors: producer, consumer</li> <li>Conformance: full</li> <li>Supported RDF libraries: Apache Jena, RDF4J</li> </ul> </li> </ul>"},{"location":"specification/streaming/","title":"Jelly gRPC streaming protocol specification","text":"<p>This document is the specification of the Jelly gRPC streaming protocol (publish/subscribe mechanism). It is intended for implementers of Jelly libraries and applications. If you are looking for a user-friendly introduction to Jelly, see the Jelly index page.</p> <p>This document is accompanied by the Jelly Protobuf reference and the Protobuf definition itself (<code>grpc.proto</code>).</p> <p>The following assumptions are used in this document:</p> <ul> <li>This document uses the specification for the Jelly serialization format.</li> <li>All strings in the mentioned Protobuf messages are assumed to be UTF-8 encoded.</li> <li>Standard gRPC status codes are used, as defined in gRPC documentation.</li> </ul> Document information Author: Piotr Sowi\u0144ski (Ostrzyciel) Version: 1.0.0 Date: August 24, 2024 Permanent URL: <code>https://w3id.org/jelly/1.0.0/specification/streaming</code> Document status: Stable specification <p>Info</p> <p>The key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\",  \"MAY\", and \"OPTIONAL\" in this document are to be interpreted as described in RFC 2119.</p> <p>Note</p> <p>The \"Note\" blocks in this document are not part of the specification, but rather provide additional information for implementers.</p>"},{"location":"specification/streaming/#conformance","title":"Conformance","text":"<p>Implementations MAY choose to implement only a subset of the following specification. In this case, they SHOULD clearly specify which parts of the specification they implement. In the rest of this specification, the keywords \"MUST\", \"MUST NOT\", etc. refer to full (not partial) implementations.</p>"},{"location":"specification/streaming/#versioning","title":"Versioning","text":"<p>The streaming protocol follows the Semantic Versioning 2.0 scheme. The version of the gRPC streaming protocol is equal to the version of the corresponding serialization format (1:1 equivalence). The version of the protocol is specified in the stream options \u2013 see the serialization specification for details.</p> <p>Note</p> <p>Releases of the protocol are published on GitHub.</p>"},{"location":"specification/streaming/#backward-compatibility","title":"Backward compatibility","text":"<p>Implementations SHOULD ensure backward compatibility. To achieve backward compatibility, the implementation MUST be able to respond to all RPCs from the previous releases of the protocol with the same MAJOR version. The implementation MAY also be able to respond to RPCs from previous releases of the protocol with a different MAJOR version.</p> <p>Note</p> <p>The protocol is designed in such a way that you don't need to worry about backward compatibility. The only thing you need to do is to implement the latest version of the protocol, and you will automatically get backward compatibility with all previous versions (of the same MAJOR).</p>"},{"location":"specification/streaming/#forward-compatibility","title":"Forward compatibility","text":"<p>Forward compatibility is not guaranteed. Implementations MAY be able to respond to RPCs from future releases of the protocol with the same MAJOR version. Implementations MAY also be able to respond to RPCs from future releases of the protocol with a different MAJOR version.</p>"},{"location":"specification/streaming/#actors-and-implementations","title":"Actors and implementations","text":"<p>The Jelly gRPC streaming protocol assumes there to be two actors: the server and the client. These actors can both play the role of the producer or the consumer of the stream (see serialization specification), depending on the direction of the stream.</p> <p>Implementations may include only the server, only the client, or both.</p>"},{"location":"specification/streaming/#protocol-specification","title":"Protocol specification","text":"<p>The protocol specifies a simple publish/subscribe mechanism topics identified with UTF-8 strings. The client can subscribe to a topic and receive messages published to that topic by the server. The client can also publish messages to a topic.</p> <p>The described protocol is implemented as a gRPC service <code>RdfStreamService</code> (reference).</p> <p>Note</p> <p>The protocol does not specify what happens to the messages on the server \u2013 this is NOT a broker or message queue specification. The protocol is meant to enable point-to-point communication, but can also be used to implement a broker or a similar service (see Usage notes below).</p> <p>You can also ignore the topics and use the protocol as a simple streaming protocol.</p>"},{"location":"specification/streaming/#topics","title":"Topics","text":"<p>Topics are identified with UTF-8 strings. The topic string MUST be valid UTF-8. There are no further restrictions on the topic string.</p> <p>Note</p> <p>The topic can be whatever you like \u2013 it can also be empty. It is up the user to decide what to use the topics for, or if to use them at all.</p>"},{"location":"specification/streaming/#subscribing-to-a-stream","title":"Subscribing to a stream","text":"<p>The client subscribes to a stream from the server with the <code>SubscribeRdf</code> RPC (reference). The RPC is initiated with an <code>RdfStreamSubscribe</code> message (reference) from the client. The message includes two OPTIONAL fields:</p> <ul> <li><code>topic</code> (1) \u2013 the topic to subscribe to. The default is an empty string.</li> <li><code>options</code> (2) \u2013 the stream options (<code>RdfStreamOptions</code>). The default is an empty message.</li> </ul> <p>The server MUST respond with either a stream of <code>RdfStreamFrame</code> messages or an error.</p>"},{"location":"specification/streaming/#stream-options-handling","title":"Stream options handling","text":"<p>The client MAY request specific options for the stream it subscribes to. In that case, the client MUST include the <code>options</code> field in the <code>RdfStreamSubscribe</code> message. The server SHOULD respond with a stream that uses options that are compatible with the options requested by the client. If the server cannot respond with a stream that uses options that are compatible with the options requested by the client, the server MUST respond with the <code>INVALID_ARGUMENT</code> error.</p> <p>The following rules are used to determine if the options are compatible. All rules MUST be satisfied for the options to be compatible.</p> Option Client request Server response <code>stream_name</code> <code>x</code> MAY be <code>x</code> <code>physical_type</code> <code>x</code> MUST be <code>x</code> <code>generalized_statements</code> <code>x</code> MUST be <code>x</code> or false <code>use_repeat</code> <code>x</code> MUST be <code>x</code> or false <code>rdf_star</code> <code>x</code> MUST be <code>x</code> or false <code>max_name_table_size</code> <code>x</code> MUST be &lt;= <code>x</code> <code>max_prefix_table_size</code> <code>x</code> MUST be &lt;= <code>x</code> <code>max_datatype_table_size</code> <code>x</code> MUST be &lt;= <code>x</code> <code>logical_type</code> <code>x</code> MAY be <code>x</code> <code>version</code> <code>x</code> MUST be &lt;= <code>x</code> <p>Note</p> <p>The server should implement some limits for the stream options it supports, for example the maximum size of the name table. Otherwise, a client may request a name table that takes up all the server's memory.</p> <p>Logical stream type handling is entirely dependent on the server implementation:</p> <ol> <li>The server MAY respect the client's request in the <code>logical_type</code> field in the stream options and respond with the same type.</li> <li>The server MAY respect the client's request in the <code>logical_type</code> field in the stream options and respond with a subtype of the requested type.</li> <li>The server MAY ignore the <code>logical_type</code> field in the client request and respond with its own type or with no type at all.</li> <li>The server MAY respond with an <code>INVALID_ARGUMENT</code> error if the client requests a type that the server does not support with the specified physical stream type.</li> </ol> <p>Note</p> <p>How you implement this behavior depends on your use case, possibly combining the above options. For example, you may want to allow the client to request a specific logical type, but only if it is compatible with the physical type. Or, if your server supports stream type conversion, you may want to allow the client to request a specific logical type and let the server handle the conversion.</p>"},{"location":"specification/streaming/#publishing-a-stream","title":"Publishing a stream","text":"<p>The client publishes a stream to the server with the <code>PublishRdf</code> RPC (reference). The RPC is initiated with a stream of <code>RdfStreamFrame</code> messages from the client. The stream MUST include at least one message. The first frame MUST include a row with the stream options as the first row. After the stream successfully completes, the server MUST respond with the <code>RdfStreamReceived</code> message (reference).</p> <p>If the server cannot handle the stream with the specified options, the server MUST respond with the <code>INVALID_ARGUMENT</code> error.</p>"},{"location":"specification/streaming/#usage-notes","title":"Usage notes","text":"<p>This section is not part of the specification.</p> <p>The protocol is deliberately very general and unrestrictive. The pub/sub mechanism can be used in a number of ways, possibly extending the existing base protocol. The following are some examples of how the protocol can be used:</p> <ul> <li>Server publishing a number of streams, each with a different topic.</li> <li>RDF stream broker or message queue \u2013 the server acts as a \"hub\" aggregating RDF data sent to a topic by clients, and then forwarding it to other clients.</li> <li>Microservice chains \u2013 one service can process an RDF stream, forward it to another service, etc.</li> </ul> <p>These use cases can be implemented with the protocol as-is, or by extending the protocol with additional messages and/or RPCs. In either case, the protocol provides a base layer for compatibility between different implementations.</p>"},{"location":"specification/streaming/#stream-frame-size","title":"Stream frame size","text":"<p>This section is not part of the specification.</p> <p>The size of the stream frame is not limited by the protocol, nor by gRPC itself. However, many gRPC implementations have a limit on the size of the message at around 4 MB. It is recommended to use much smaller messages (e.g., 100 KB), which will also make it easier to serialize and deserialize the messages. For most use cases of RDF graph/dataset streams (like IoT messaging), this should be sufficient. Otherwise, you will have to split the frames into smaller messages.</p>"},{"location":"specification/streaming/#long-running-streams-and-keep-alive-pings","title":"Long-running streams and keep-alive pings","text":"<p>This section is not part of the specification.</p> <p>The gRPC protocol does support long-running streams, but due to how it's implemented (over HTTP/2 and TCP), some networking equipment or network stack implementations may terminate a connection if there is no activity for a long time. If you are working with a stream that can be \"quiet\" for more than a minute, this may be a problem.</p> <p>To prevent this, HTTP/2 ping frames can be used by the server to periodically ping the client, keeping the connection alive. This is implemented in many HTTP/2 libraries. For example in Apache Pekko HTTP, one needs to set the <code>pekko.http.server.http2.ping-interval</code> configuration option to a non-zero value. This is done in Jelly-JVM's gRPC module by default.</p>"},{"location":"specification/streaming/#implementations","title":"Implementations","text":"<p>This section is not part of the specification.</p> <p>The following implementations of the Jelly gRPC streaming protocol specification are available:</p> <ul> <li>Jelly-JVM (Scala) implementation<ul> <li>Specification version: 1.0.0</li> <li>Partial (boilerplate) implementation based on Apache Pekko gRPC. Requires the end user to implement their own code for handling the streams.</li> </ul> </li> </ul>"}]}