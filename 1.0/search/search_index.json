{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Test \u2013 index.md</p>"},{"location":"contributing/","title":"Contributing","text":"<p>TODO</p>"},{"location":"licensing/","title":"Licensing and citation","text":"<p>TODO</p>"},{"location":"performance/","title":"Performance","text":"<p>link to benchmarks repo</p>"},{"location":"user-guide/","title":"Jelly user guide","text":"<p>Jelly is a high-performance protocol for streaming and non-streaming RDF data. It is designed to be simple, fast, and easy to implement. This guide will help you get started with Jelly.</p> <p>Jelly uses Protocol Buffers 3 as the basis of its serialization. This means that you can quickly create a new Jelly implementation using code generation. You can also use an existing implementation, such as the JVM (Scala) implementation.</p>"},{"location":"user-guide/#what-can-it-do","title":"What can it do?","text":"<p>Jelly is designed to be a protocol for streaming RDF data, but it can also be used with \"classic\", static RDF data. The main design goals of Jelly are speed, simplicity, and wide coverage of use cases. </p> <ul> <li>Jelly can work with any RDF data, including RDF-star, RDF 1.1, and generalized RDF.</li> <li>Jelly can be used to represent streams of triples, quads, graphs, or datasets.</li> <li>Jelly can also be used to represent a single graph or dataset.</li> <li>Jelly can be used for streaming data over the network (e.g., with MQTT, Kafka, gRPC), but also for working with flat files.</li> <li>Jelly can compress RDF data on the fly, without having to know the data in advance.</li> <li>Jelly is super-fast and lightweight, scaling both down to embedded devices and up to high-performance servers.</li> </ul>"},{"location":"user-guide/#how-to-use-it","title":"How to use it?","text":"<p>To use Jelly you firstly need an implementation of the protocol. There is currently one implementation available: Jelly JVM (Scala), which supports both Apache Jena and Eclipse RDF4J. It also has support for reactive streams and gRPC.</p> <p>The implementation will support several stream types and patterns that you can use. Which stream type you choose depends on your use case (see stream types below).</p> <p>All stream types use the same concept of stream frames \u2013 discrete elements into which the stream is divided. Each frame contains a number of rows, which are the actual RDF data (RDF triples, quads, etc.). Jelly does not define the semantics of stream frames \u2013 it's up to you to decide what they mean (see examples below).</p> <p>Why doesn't Jelly define the semantics of stream frames?</p> <p>There are many, many ways in which streams of RDF data can be used \u2013 there are different use cases, network protocols, QoS settings, ordering guarantees, stream semantics, etc. Picking specific semantics for stream frames would hopelessly overcomplicate the protocol and make it less useful in some use cases.</p> <p>Jelly tries to make as few assumptions as possible about the streams to ensure it is widely applicable. It is the responsibility of the end users to define the semantics of stream frames for their use case. To help with that, this user guide contains some common patterns and examples.</p>"},{"location":"user-guide/#stream-types","title":"Stream types","text":"<ul> <li>Triple stream: A stream of triple statements. You can use it to represent:<ul> <li>A single unnamed RDF graph \u2013 stream frames are just batches of triples.</li> <li>A stream of triple statements \u2013 stream frames are just batches of triples.</li> <li>A stream of default (unnamed) RDF graphs \u2013 each stream frame corresponds to a different RDF graph.</li> </ul> </li> <li>Quad stream: A stream of quad (triple with graph node) statements. You can use it to represent:<ul> <li>A single RDF dataset \u2013 stream frames are just batches of quads.</li> <li>A stream of quad statements \u2013 stream frames are just batches of quads.</li> <li>A stream of RDF datasets \u2013 each stream frame corresponds to a different RDF dataset.</li> </ul> </li> <li>Graph stream: A stream of triples grouped into graphs (named or unnamed). You can use it to represent:<ul> <li>A single RDF dataset \u2013 stream frames are just batches of graphs (possibly partial graphs).</li> <li>A stream of named RDF graphs \u2013 each stream frame corresponds to a different named graph.</li> <li>A stream of RDF datasets \u2013 each stream frame corresponds to a different RDF dataset.</li> </ul> </li> </ul>"},{"location":"user-guide/#common-patterns-cookbook","title":"Common patterns cookbook","text":"<p>Below you will find some common patterns for using Jelly. These are just examples \u2013 you can use Jelly in many other ways. All of the presented patterns are supported in the Jelly JVM (Scala) implementation with the Reactive Streaming module.</p>"},{"location":"user-guide/#triple-stream-just-a-bunch-of-triples","title":"Triple stream \u2013 \"just a bunch of triples\"","text":"<p>Let's say you want to stream a lot of triples from A to B \u2013 maybe you're doing some kind of data migration, or you're sending data to a data lake. You don't care about the graph they belong to \u2013 you just want to send a bunch of triples.</p> <p>You can use a triple stream, batching the triples into frames of an arbitrary size (let's say, 1000 triples each):</p> Example (click to expand) <ul> <li>Stream frame 1<ul> <li>Stream options</li> <li>Triple 1</li> <li>Triple 2</li> <li>...</li> <li>Triple 1000</li> </ul> </li> <li>Stream frame 2<ul> <li>Triple 1001</li> <li>Triple 1002</li> <li>...</li> <li>Triple 2000</li> </ul> </li> <li>...</li> </ul> <p>You can then send these frames one-by-one over gRPC or Kafka, or write them to a file. The consumer will be able to read the triples one frame at a time, without having to know how many triples there are in total.</p>"},{"location":"user-guide/#triple-stream-a-stream-of-graphs","title":"Triple stream \u2013 \"a stream of graphs\"","text":"<p>In this case we have an IoT sensor that periodically emits an RDF graph that describes what the sensor saw (something like SOSA/SSN). The graphs may be of different sizes (depending on what the sensor saw) and they can be emitted at different rates (depending on how often the sensor is triggered). We want to stream these graphs to a server that will process them in real-time with no additional latency.</p> <p>You can use a triple stream, where the stream frames correspond to different unnamed (default) graphs:</p> Example (click to expand) <ul> <li>Stream frame 1<ul> <li>Stream options</li> <li>Triple 1 (of graph 1)</li> <li>Triple 2 (of graph 1)</li> <li>...</li> <li>Triple 134 (of graph 1)</li> </ul> </li> <li>Stream frame 2<ul> <li>Triple 1 (of graph 2)</li> <li>Triple 2 (of graph 2)</li> <li>...</li> <li>Triple 97 (of graph 2)</li> </ul> </li> <li>...</li> </ul> <p>The consumer will be able to read the graphs one frame at a time, without having to know how many graphs there are in total.</p> <p>RiverBench uses this pattern for distributing its triple streams (see example). Note that in RiverBench the stream may be equivalently considered \"just a bunch of triples\" \u2013 the serialization is the same, it only depends on the interpretation on the side of the consumer.</p>"},{"location":"user-guide/#quad-stream-just-a-bunch-of-quads","title":"Quad stream \u2013 \"just a bunch of quads\"","text":"<p>You want to stream a lot of quads \u2013 similar to the \"just a bunch of triples\" case above, but you also want to include the graph node. You can use a quad stream, batching the quads into frames of an arbitrary size (let's say, 1000 quads each):</p> Example (click to expand) <ul> <li>Stream frame 1<ul> <li>Stream options</li> <li>Quad 1</li> <li>Quad 2</li> <li>...</li> <li>Quad 1000</li> </ul> </li> <li>Stream frame 2<ul> <li>Quad 1001</li> <li>Quad 1002</li> <li>...</li> <li>Quad 2000</li> </ul> </li> <li>...</li> </ul> <p>The mechanism is exactly the same as with a triple stream.</p>"},{"location":"user-guide/#quad-stream-a-stream-of-datasets","title":"Quad stream \u2013 \"a stream of datasets\"","text":"<p>You want to stream RDF datasets \u2013 similar to the \"a stream of graphs\" case above, but your elements are entire datasets. You can use a quad stream, where the stream frames correspond to different datasets:</p> Example (click to expand) <ul> <li>Stream frame 1<ul> <li>Stream options</li> <li>Quad 1 (of dataset 1)</li> <li>Quad 2 (of dataset 1)</li> <li>...</li> <li>Quad 454 (of dataset 1)</li> </ul> </li> <li>Stream frame 2<ul> <li>Quad 1 (of dataset 2)</li> <li>Quad 2 (of dataset 2)</li> <li>...</li> <li>Quad 323 (of dataset 2)</li> </ul> </li> <li>...</li> </ul> <p>The mechanism is exactly the same as with a triple stream of graphs.</p> <p>RiverBench uses this pattern for distributing its quad and graph streams (see example). Note that in RiverBench the stream may be equivalently considered \"just a bunch of quads\" \u2013 the serialization is the same, it only depends on the interpretation on the side of the consumer.</p>"},{"location":"user-guide/#graph-stream-just-a-bunch-of-named-graphs","title":"Graph stream \u2013 \"just a bunch of named graphs\"","text":"<p>This a slightly different take on the problem of \"just a bunch of quads\" \u2013 you also want to transmit what is essentially an RDF dataset, but instead of sending individual quads, you want to send it graph-by-graph. This makes most sense if your data changes on a per-graph basis, or you are streaming a static RDF dataset.</p> <p>You can use a graph stream, batching the triples in the graphs into frames of an arbitrary size (let's say, 1000 triples each):</p> Example (click to expand) <ul> <li>Stream frame 1<ul> <li>Stream options</li> <li>Start graph (named 1)</li> <li>Triple 1 (of graph 1)</li> <li>Triple 2 (of graph 1)</li> <li>...</li> <li>Triple 134 (of graph 1)</li> <li>End graph</li> <li>Start graph (named 2)</li> <li>Triple 1 (of graph 2)</li> <li>Triple 2 (of graph 2)</li> <li>...</li> <li>Triple 97 (of graph 2)</li> </ul> </li> <li>Stream frame 2<ul> <li>Triple 98 (of graph 2)</li> <li>...</li> <li>Triple 130 (of graph 2)</li> <li>End graph</li> <li>Start graph (named 3)</li> <li>Triple 1 (of graph 3)</li> <li>Triple 2 (of graph 3)</li> <li>...</li> <li>Triple 77 (of graph 3)</li> <li>End graph</li> <li>Start graph (named 4)</li> <li>Triple 1 (of graph 4)</li> <li>Triple 2 (of graph 4)</li> <li>...</li> <li>Triple 21 (of graph 4)</li> <li>End graph</li> </ul> </li> <li>...</li> </ul> <p>Notice that one graph can span multiple stream frames, and one stream frame can contain multiple graphs. The consumer will be able to read the graphs one frame at a time, without having to know how many graphs there are in total.</p>"},{"location":"user-guide/#graph-stream-a-stream-of-datasets","title":"Graph stream \u2013 \"a stream of datasets\"","text":"<p>You want to stream RDF datasets \u2013 for example using the RSP Data Model, where each element is a named graph and a bunch of statements about this graph in the default graph. You can use a graph stream, where the stream frames correspond to different datasets:</p> Example (click to expand) <ul> <li>Stream frame 1<ul> <li>Stream options</li> <li>Start graph (default)    </li> <li>Triple 1 (of default graph)</li> <li>Triple 2 (of default graph)</li> <li>...</li> <li>Triple 134 (of default graph)</li> <li>End graph</li> <li>Start graph (named)</li> <li>Triple 1 (of named graph)</li> <li>Triple 2 (of named graph)</li> <li>...</li> <li>Triple 97 (of named graph)</li> <li>End graph</li> </ul> </li> <li>Stream frame 2<ul> <li>Start graph (default)</li> <li>Triple 1 (of default graph)</li> <li>Triple 2 (of default graph)</li> <li>...</li> <li>Triple 77 (of default graph)</li> <li>End graph</li> <li>Start graph (named)</li> <li>Triple 1 (of named graph)</li> <li>Triple 2 (of named graph)</li> <li>...</li> <li>Triple 21 (of named graph)</li> <li>End graph</li> </ul> </li> <li>...</li> </ul> <p>Of course each stream frame can contain more than one named graph, and the graphs can be of different sizes.</p>"},{"location":"user-guide/#ordering-and-delivery-guarantees","title":"Ordering and delivery guarantees","text":"<p>To be able to compress RDF streams on-the-fly, Jelly requires that stream frames are kept strictly in order (see also the spec). This is because the compression algorithm updates its lookup tables dynamically over the course of the stream, and a given frame depends on the lookups defined in previous frames. If the frames are out of order, the compression may fail.</p> <p>There are use cases where it's hard to guarantee strict ordering of messages, such as IoT messaging (e.g., MQTT with QoS 0) or high-throughput streams with parallel partitions (e.g., Kafka). In these cases you may want to employ one of these strategies:</p> <ul> <li>Emit shared lookup tables at the start of the stream: If you know the vocabulary of the stream, you can emit most of the content of the lookup tables at the start of the stream, and then only update the lookup elements that vary frame-to-frame, keeping the updates local to the frame. This strategy is especially useful in IoT scenarios, where the vocabulary is usually known in advance. You don't need to modify the consumer in this case.<ul> <li>A variation of this strategy is to communicate the lookup tables over a separate channel before starting the stream. This is useful if you can't guarantee that the lookup tables will be delivered before the stream frames.</li> </ul> </li> <li>Use a \"frame ID\" to keep track of the order: If you can't guarantee the order of the frames, you can add a \"frame ID\" to each frame, which will allow the consumer to reorder the frames before processing them. This strategy is useful in high-throughput scenarios, where you can't guarantee the order of the frames. You will need to modify the consumer to reorder the frames before processing them. However, handling failures in this scenario may be complicated.</li> <li>Use partitions that are guaranteed to be in-order: If you can't guarantee the order of the frames, you can use partitions that are guaranteed to be in-order (e.g., Kafka partitions). Then, each partition should have its own set of lookups (essentially treating each partition as a separate stream in Jelly's terms). This strategy is useful in high-throughput scenarios.</li> </ul> <p>Note that Jelly by default also assumes that frames are delivered at least once. At-least-once delivery is good enough (as long as the order is kept), as lookup updates are idempotent \u2013 you may only need to de-duplicate the frames afterwards. At-most-once delivery requires you to make the frames independent of each other, such as with the IoT strategy above.</p>"},{"location":"user-guide/#implementing-jelly","title":"Implementing Jelly","text":"<p>Note</p> <p>This section is intended only for those who want to write a new Jelly implementation from scratch. It's much easier to use an existing implementation, such as the JVM (Scala) implementation.</p> <p>Implementing Jelly from scratch is greatly simplified by the existing Protobuf and RDF libraries. Essentially, the only thing you'll need to do is to glue them together:</p> <ul> <li>Find a Protobuf library for your language. You can find a list of official Protobuf implementations here and a list of community-maintained implementations here.</li> <li>Use the library to generate the code for the Jelly messages (this usually involves using <code>protoc</code>). You can find the Protobuf definitions in the jelly-protobuf repository.</li> <li>Find an RDF library for your language. You can find a list of RDF libraries here.</li> <li>Implement conversions to and/or from the RDF library's data structures. You can find an example of the conversion code in the Jelly JVM (Scala) implementation (<code>core</code>, <code>jena</code>, and <code>rdf4j</code> modules).</li> <li>In the implementation follow the specification to ensure compatibility.</li> </ul> <p>That's it! You may also want to implement streaming facilities, such as Reactive Streams in Java/Scala. Implementing the gRPC publish/subscribe mechanism follows a very similar procedure \u2013 many Protobuf libraries have built-in support for gRPC with code generation.</p>"},{"location":"jvm/","title":"Jelly JVM (Scala) implementation","text":"<p>Jelly JVM is an implementation of the Jelly serialization format and the gRPC streaming protocol for the Java Virtual Machine (JVM), written in Scala 3. The supported RDF libraries are Apache Jena and Eclipse RDF4J.</p> <p>This collection of libraries aims to provide the full stack of utilities for fast and scalable RDF streaming with the Jelly protocol.</p> <p>Getting started</p> <p>See the Getting started guide for a quick introduction to the Jelly JVM implementation.</p>"},{"location":"jvm/#library-modules","title":"Library modules","text":"<p>The implementation is split into a few modules that can be used separately:</p> <ul> <li> <p><code>jelly-core</code> \u2013 implementation of the Jelly serialization format (using the scalapb library), along with generic utilities for converting the deserialized RDF data to/from the representations of RDF libraries (like Apache Jena or RDF4J). </p> <ul> <li> </li> </ul> </li> <li> <p><code>jelly-jena</code> \u2013 conversions and interop code for the Apache Jena library.</p> <ul> <li> </li> </ul> </li> <li> <p><code>jelly-rdf4j</code> \u2013 conversions and interop code for the RDF4J library.</p> <ul> <li> </li> </ul> </li> <li> <p><code>jelly-stream</code> \u2013 utilities for building Reactive Streams of RDF data (based on Pekko Streams). Useful for integrating with gRPC or other streaming protocols (e.g., Kafka, MQTT).</p> <ul> <li> </li> </ul> </li> <li> <p><code>jelly-grpc</code> \u2013 implementation of a gRPC client and server for the Jelly gRPC streaming protocol.</p> <ul> <li> </li> </ul> </li> </ul>"},{"location":"jvm/#compatibility","title":"Compatibility","text":"<p>The Jelly JVM implementation is compatible with Java 11 and newer. Java 11, 17, and 21 are tested in CI and are guaranteed to work.</p> <p>The following table shows the compatibility of the Jelly JVM implementation with other libraries:</p> Jelly Scala Java RDF4J Apache Jena Apache Pekko 1.0.x 3.3.1 11\u201321 4.x 4.x 1.x"},{"location":"jvm/#documentation","title":"Documentation","text":"<p>Below is a list of all documentation pages about Jelly JVM. You can also browse the Javadoc using the badges in the module list above. The documentation uses examples written in Scala, but the libraries can be used from Java as well.</p> <ul> <li>Getting started</li> <li>User guide<ul> <li>Apache Jena integration</li> <li>RDF4J integration</li> <li>Reactive streaming</li> <li>gRPC</li> </ul> </li> <li>Developer guide<ul> <li>Releases</li> <li>Implementing Jelly for other libraries</li> </ul> </li> </ul>"},{"location":"jvm/getting-started/","title":"Jelly JVM \u2013 getting started","text":"<p>Compatibility \u2013 Java 11 \u2013 21. 11, 17, 21 are tested in CI.</p>"},{"location":"jvm/grpc/","title":"User guide \u2013 gRPC","text":""},{"location":"jvm/grpc/#example-grpc-pubsub","title":"Example \u2013 gRPC pub/sub","text":""},{"location":"jvm/implementation/","title":"Developer guide \u2013 implementing conversions for other libraries","text":"<p>Currently converters for the two most popular RDF JVM libraries are implemented \u2013 RDF4J and Jena. But it is possible to implement your own converters and adapt the Jelly serialization code to any RDF library with little effort.</p> <p>To do this, you will need to implement three traits (interfaces in Java) from the <code>jelly-core</code> module: <code>ProtoEncoder</code>, <code>ProtoDecoderConverter</code>, and <code>ConverterFactory</code>.</p> <ul> <li> <p>ProtoEncoder (serialization)</p> <ul> <li><code>get*</code> methods deconstruct triple statements, quad statements, and quoted triples (RDF-star). You can make them <code>inline</code>.</li> <li><code>nodeToProto</code> and <code>graphToProto</code> should translate into Jelly's representation all possible variations of RDF terms in the SPO and G positions, respectively.</li> <li>Example implementation for Jena: JenaProtoEncoder</li> <li>You can skip implementing this trait if you don't need serialization.</li> <li>You can also skip implementing some methods (make them throw an exception or return null) if, for example, you don't want to work with quads or RDF-start.</li> </ul> </li> <li> <p>ProtoDecoderConverter (deserialization)</p> <ul> <li>The <code>make*</code> methods should construct new RDF terms and statements. You can make them <code>inline</code>.</li> <li>Example implementation for Jena: JenaDecoderConverter</li> <li>You can skip implementing this trait if you don't need deserialization.</li> <li>You can also skip implementing some methods (make them throw an exception or return null) if, for example, you don't want to work with quads or RDF-start.</li> </ul> </li> <li> <p>ConverterFactory \u2013 wrapper that allows other modules to use your converter.</p> <ul> <li>The methods should just return new instances of your <code>ProtoEncoder</code> and <code>ProtoDecoderConverter</code> implementations.</li> <li>Example for Jena: JenaConverterFactory</li> </ul> </li> </ul>"},{"location":"jvm/reactive/","title":"User guide \u2013 reactive streaming","text":"<p>TODO</p>"},{"location":"jvm/reactive/#example-streaming-with-kafka","title":"Example: streaming with Kafka","text":""},{"location":"jvm/reactive/#byte-streams","title":"Byte streams","text":"<p>TODO</p> <p>(referenced by specification/serialization.md)</p>"},{"location":"jvm/releases/","title":"Developer guide \u2013 releases","text":""},{"location":"jvm/releases/#full-versioned-releases","title":"Full (versioned) releases","text":"<p>Full (versioned) releases are created manually and follow the Semantic Versioning scheme for binary compatibility.</p> <p>To create a new tagged release (example for version 1.2.3): <pre><code>$ git checkout main\n$ git pull\n$ git tag v1.2.3\n$ git push origin v1.2.3\n</code></pre></p> <p>The rest (packaging and release creation) will be handled automatically by the CI. The release will be pushed to Maven Central.</p>"},{"location":"jvm/releases/#snapshot-releases","title":"Snapshot releases","text":"<p>Snapshot releases are triggered automatically by commits in the <code>main</code> branch. Snapshots are pushed to the Sonatype snapshot repository.</p>"},{"location":"specification/","title":"Jelly protocol specification","text":"<p>The Jelly protocol consists of two parts: the gRPC streaming protocol and the serialization format. The serialization format is the basis for Jelly, specifying how to turn RDF data into bytes and back. The gRPC streaming protocol defines a publish/subscribe mechanism for exchanging RDF data between a client and a server, using gRPC.</p> <p>See the user guide for a friendlier introduction to Jelly.</p> <p>See the specification pages for more details:</p> <ul> <li>Serialization format specification</li> <li>gRPC streaming protocol specification</li> <li>Protobuf reference</li> <li>Protobuf sources</li> <li>File extension and media type</li> </ul>"},{"location":"specification/media-type/","title":"File extension and media type","text":"<p>Jelly is not tied to any specific file extension and does not have a registered media type. However, you can use the following:</p> <ul> <li>File extension: <code>.jelly</code></li> <li>Media type: <code>application/x-jelly-rdf</code></li> </ul> <p>The files should be saved in the delimited variant of Jelly.</p>"},{"location":"specification/media-type/#see-also","title":"See also","text":"<ul> <li>Serialization format specification</li> </ul>"},{"location":"specification/protobuf-source/","title":"Protobuf sources","text":"<p>Below you will find the Protocol Buffers definitions for the Jelly serialization format and the Jelly gRPC streaming protocol. The original files are hosted on GitHub and all releases can be found here.</p> <p>Human-readable reference for these definitions can be found here.</p> <p>The following code is licensed under the Apache License, Version 2.0.</p>"},{"location":"specification/protobuf-source/#rdfproto","title":"<code>rdf.proto</code>","text":"<pre><code>syntax = \"proto3\";\npackage eu.ostrzyciel.jelly.core.proto.v1;\n\n// Jelly RDF serialization with Protocol Buffers.\n// Protocol version: 1.0.0\n\n// RDF IRIs\n// Either prefix_id or name_id can be zero if the prefix or the suffix are not used.\nmessage RdfIri {\n  // 1-based, refers to an entry in the prefix lookup.\n  uint32 prefix_id = 1;\n  // 1-based, refers to an entry in the name lookup.\n  uint32 name_id = 2;\n}\n\n// RDF literals\nmessage RdfLiteral {\n  // The lexical form of the literal.\n  string lex = 1;\n\n  // Literal kind \u2013 exactly one of these fields must be set.\n  oneof literalKind {\n    // Simple literal with datatype xsd:string.\n    RdfLiteralSimple simple = 2;\n    // Language-tagged string.\n    string langtag = 3;\n    // Typed literal. The datatype is a reference to an entry in the datatype lookup.\n    uint32 datatype = 4;\n  }\n}\n\n// Empty message indicating a simple literal\nmessage RdfLiteralSimple {\n}\n\n// Empty message indicating a repeated term from the previous statement.\nmessage RdfRepeat {\n}\n\n// RDF terms\nmessage RdfTerm {\n  // Exactly one of these fields must be set.\n  oneof term {\n    // IRI\n    RdfIri        iri = 1;\n    // Blank node\n    string        bnode = 2;\n    // Literal\n    RdfLiteral    literal = 3;\n    // RDF-star quoted triple\n    RdfTriple     triple_term = 4;\n    // Repeated term from the previous statement. Only valid in statements, not quoted triples.\n    RdfRepeat     repeat = 10;\n  }\n}\n\n// Empty message indicating the default RDF graph.\nmessage RdfDefaultGraph {\n}\n\n// RDF graph nodes\nmessage RdfGraph {\n  // Exactly one of these fields must be set.\n  oneof graph {\n    // IRI\n    RdfIri           iri = 1;\n    // Blank node\n    string           bnode = 2;\n    // Literal \u2013 only valid for generalized RDF streams\n    RdfLiteral       literal = 3;\n    // Default graph\n    RdfDefaultGraph  default_graph = 4;\n    // Repeated term \u2013 only valid in a QUADS stream\n    RdfRepeat        repeat = 10;\n  }\n}\n\n// RDF triple\nmessage RdfTriple {\n  // Triple subject\n  RdfTerm s = 1;\n  // Triple predicate\n  RdfTerm p = 2;\n  // Triple object\n  RdfTerm o = 3;\n}\n\n// RDF quad\nmessage RdfQuad {\n  // Quad subject\n  RdfTerm  s = 1;\n  // Quad predicate\n  RdfTerm  p = 2;\n  // Quad object\n  RdfTerm  o = 3;\n  // Quad graph node\n  RdfGraph g = 4;\n}\n\n// Start of a graph in a GRAPHS stream\nmessage RdfGraphStart {\n  RdfGraph graph = 1;\n}\n\n// End of a graph in a GRAPHS stream\nmessage RdfGraphEnd {\n}\n\n// Entry in the name lookup table\nmessage RdfNameEntry {\n  // 1-based identifier\n  uint32 id = 1;\n  // Value of the name (UTF-8 encoded)\n  string value = 2;\n}\n\n// Entry in the prefix lookup table\nmessage RdfPrefixEntry {\n  // 1-based identifier\n  uint32 id = 1;\n  // Value of the prefix (UTF-8 encoded)\n  string value = 2;\n}\n\n// Entry in the datatype lookup table\nmessage RdfDatatypeEntry {\n  // 1-based identifier\n  uint32 id = 1;\n  // Value of the datatype (UTF-8 encoded)\n  string value = 2;\n}\n\n// RDF stream options\nmessage RdfStreamOptions {\n  // Name of the stream (completely optional).\n  // This may be used for, e.g., topic names in a pub/sub system.\n  string stream_name = 1;\n  // Type of the stream (required)\n  RdfStreamType stream_type = 2;\n  // Whether the stream may contain generalized triples, quads, or datasets\n  bool generalized_statements = 3;\n  // Whether RdfRepeat will be used\n  bool use_repeat = 4;\n  // Whether the stream may contain RDF-star statements\n  bool rdf_star = 5;\n  // Maximum size of the name lookup table\n  uint32 max_name_table_size = 9;\n  // Maximum size of the prefix lookup table\n  uint32 max_prefix_table_size = 10;\n  // Maximum size of the datatype lookup table\n  uint32 max_datatype_table_size = 11;\n  // Protocol version (required)\n  // For Jelly 1.0.x value must be 1.\n  // For custom extensions, the value must be 1000 or higher.\n  uint32 version = 15;\n}\n\n// RDF stream type\nenum RdfStreamType {\n  // Unspecified stream type \u2013 invalid\n  RDF_STREAM_TYPE_UNSPECIFIED = 0;\n  // RDF triples\n  RDF_STREAM_TYPE_TRIPLES = 1;\n  // RDF quads\n  RDF_STREAM_TYPE_QUADS = 2;\n  // RDF triples grouped in graphs\n  RDF_STREAM_TYPE_GRAPHS = 3;\n}\n\n// RDF stream row\nmessage RdfStreamRow {\n  // Exactly one of these fields must be set.\n  oneof row {\n    // Stream options. Must occur at the start of the stream.\n    RdfStreamOptions options = 1;\n    // RDF triple statement.\n    // Valid in TRIPLES and GRAPHS streams.\n    RdfTriple triple = 2;\n    // RDF quad statement.\n    // Only valid in a QUADS stream.\n    RdfQuad quad = 3;\n    // Graph boundary: ends the currently transmitted graph and starts a new one\n    // Only valid in a GRAPHS stream.\n    RdfGraphStart graph_start = 4;\n    // Explicit end of a graph.\n    // Signals the consumer that the transmitted graph is complete.\n    // Only valid in a GRAPHS stream.\n    RdfGraphEnd graph_end = 5;\n    // Entry in the name lookup table.\n    RdfNameEntry name = 9;\n    // Entry in the prefix lookup table.\n    RdfPrefixEntry prefix = 10;\n    // Entry in the datatype lookup table.\n    RdfDatatypeEntry datatype = 11;\n  }\n}\n\n// RDF stream frame\nmessage RdfStreamFrame {\n  // Stream rows\n  repeated RdfStreamRow rows = 1;\n}\n</code></pre>"},{"location":"specification/protobuf-source/#grpcproto","title":"<code>grpc.proto</code>","text":"<pre><code>syntax = \"proto3\";\npackage eu.ostrzyciel.jelly.core.proto.v1;\n\n// gRPC service specifications for RDF streaming.\n// Protocol version: 1.0.0\n\nimport \"rdf.proto\";\n\n// Subscribe command sent by the client to the server.\nmessage RdfStreamSubscribe {\n  // The topic to which the client wants to subscribe (UTF-8 encoded).\n  string topic = 1;\n  // Optional: the stream options requested by the client.\n  // The server should respond with a stream that matches these options.\n  // In case that is not possible, the server must respond with the\n  // INVALID_ARGUMENT error.\n  RdfStreamOptions requested_options = 2;\n}\n\n// Acknowledgement of receiving a stream sent by the server to the client.\nmessage RdfStreamReceived {\n}\n\n// Pub/Sub service for RDF streams, to be implemented by the server.\nservice RdfStreamService {\n  // Subscribe to an RDF stream.\n  rpc SubscribeRdf (RdfStreamSubscribe) returns (stream RdfStreamFrame);\n  // Publish an RDF stream.\n  // In case the server cannot process the stream, it must respond with\n  // the INVALID_ARGUMENT error.\n  rpc PublishRdf (stream RdfStreamFrame) returns (RdfStreamReceived);\n}\n</code></pre>"},{"location":"specification/protobuf-source/#see-also","title":"See also","text":"<ul> <li>Jelly Protobuf reference</li> <li>Serialization format specification</li> <li>gRPC streaming protocol specification</li> </ul>"},{"location":"specification/reference/","title":"Protocol Documentation","text":""},{"location":"specification/reference/#table-of-contents","title":"Table of Contents","text":"<ul> <li> <p>grpc.proto</p> <ul> <li>RdfStreamReceived</li> <li> <p>RdfStreamSubscribe</p> </li> <li> <p>RdfStreamService</p> </li> </ul> </li> <li> <p>rdf.proto</p> <ul> <li>RdfDatatypeEntry</li> <li>RdfDefaultGraph</li> <li>RdfGraph</li> <li>RdfGraphEnd</li> <li>RdfGraphStart</li> <li>RdfIri</li> <li>RdfLiteral</li> <li>RdfLiteralSimple</li> <li>RdfNameEntry</li> <li>RdfPrefixEntry</li> <li>RdfQuad</li> <li>RdfRepeat</li> <li>RdfStreamFrame</li> <li>RdfStreamOptions</li> <li>RdfStreamRow</li> <li>RdfTerm</li> <li> <p>RdfTriple</p> </li> <li> <p>RdfStreamType</p> </li> </ul> </li> <li> <p>Scalar Value Types</p> </li> </ul> <p></p> <p>Top</p>"},{"location":"specification/reference/#grpcproto","title":"grpc.proto","text":""},{"location":"specification/reference/#rdfstreamreceived","title":"RdfStreamReceived","text":"<p>Acknowledgement of receiving a stream sent by the server to the client.</p> <p></p>"},{"location":"specification/reference/#rdfstreamsubscribe","title":"RdfStreamSubscribe","text":"<p>Subscribe command sent by the client to the server.</p> Field Type Label Description topic string The topic to which the client wants to subscribe (UTF-8 encoded). requested_options RdfStreamOptions Optional: the stream options requested by the client. The server should respond with a stream that matches these options. In case that is not possible, the server must respond with the INVALID_ARGUMENT error. <p></p>"},{"location":"specification/reference/#rdfstreamservice","title":"RdfStreamService","text":"<p>Pub/Sub service for RDF streams, to be implemented by the server.</p> Method Name Request Type Response Type Description SubscribeRdf RdfStreamSubscribe RdfStreamFrame stream Subscribe to an RDF stream. PublishRdf RdfStreamFrame stream RdfStreamReceived Publish an RDF stream. In case the server cannot process the stream, it must respond with the INVALID_ARGUMENT error. <p></p> <p>Top</p>"},{"location":"specification/reference/#rdfproto","title":"rdf.proto","text":""},{"location":"specification/reference/#rdfdatatypeentry","title":"RdfDatatypeEntry","text":"<p>Entry in the datatype lookup table</p> Field Type Label Description id uint32 1-based identifier value string Value of the datatype (UTF-8 encoded) <p></p>"},{"location":"specification/reference/#rdfdefaultgraph","title":"RdfDefaultGraph","text":"<p>Empty message indicating the default RDF graph.</p> <p></p>"},{"location":"specification/reference/#rdfgraph","title":"RdfGraph","text":"<p>RDF graph nodes</p> Field Type Label Description iri RdfIri IRI bnode string Blank node literal RdfLiteral Literal \u2013 only valid for generalized RDF streams default_graph RdfDefaultGraph Default graph repeat RdfRepeat Repeated term \u2013 only valid in a QUADS stream <p></p>"},{"location":"specification/reference/#rdfgraphend","title":"RdfGraphEnd","text":"<p>End of a graph in a GRAPHS stream</p> <p></p>"},{"location":"specification/reference/#rdfgraphstart","title":"RdfGraphStart","text":"<p>Start of a graph in a GRAPHS stream</p> Field Type Label Description graph RdfGraph <p></p>"},{"location":"specification/reference/#rdfiri","title":"RdfIri","text":"<p>RDF IRIs Either prefix_id or name_id can be zero if the prefix or the suffix are not used.</p> Field Type Label Description prefix_id uint32 1-based, refers to an entry in the prefix lookup. name_id uint32 1-based, refers to an entry in the name lookup. <p></p>"},{"location":"specification/reference/#rdfliteral","title":"RdfLiteral","text":"<p>RDF literals</p> Field Type Label Description lex string The lexical form of the literal. simple RdfLiteralSimple Simple literal with datatype xsd:string. langtag string Language-tagged string. datatype uint32 Typed literal. The datatype is a reference to an entry in the datatype lookup. <p></p>"},{"location":"specification/reference/#rdfliteralsimple","title":"RdfLiteralSimple","text":"<p>Empty message indicating a simple literal</p> <p></p>"},{"location":"specification/reference/#rdfnameentry","title":"RdfNameEntry","text":"<p>Entry in the name lookup table</p> Field Type Label Description id uint32 1-based identifier value string Value of the name (UTF-8 encoded) <p></p>"},{"location":"specification/reference/#rdfprefixentry","title":"RdfPrefixEntry","text":"<p>Entry in the prefix lookup table</p> Field Type Label Description id uint32 1-based identifier value string Value of the prefix (UTF-8 encoded) <p></p>"},{"location":"specification/reference/#rdfquad","title":"RdfQuad","text":"<p>RDF quad</p> Field Type Label Description s RdfTerm Quad subject p RdfTerm Quad predicate o RdfTerm Quad object g RdfGraph Quad graph node <p></p>"},{"location":"specification/reference/#rdfrepeat","title":"RdfRepeat","text":"<p>Empty message indicating a repeated term from the previous statement.</p> <p></p>"},{"location":"specification/reference/#rdfstreamframe","title":"RdfStreamFrame","text":"<p>RDF stream frame</p> Field Type Label Description rows RdfStreamRow repeated Stream rows <p></p>"},{"location":"specification/reference/#rdfstreamoptions","title":"RdfStreamOptions","text":"<p>RDF stream options</p> Field Type Label Description stream_name string Name of the stream (completely optional). This may be used for, e.g., topic names in a pub/sub system. stream_type RdfStreamType Type of the stream (required) generalized_statements bool Whether the stream may contain generalized triples, quads, or datasets use_repeat bool Whether RdfRepeat will be used rdf_star bool Whether the stream may contain RDF-star statements max_name_table_size uint32 Maximum size of the name lookup table max_prefix_table_size uint32 Maximum size of the prefix lookup table max_datatype_table_size uint32 Maximum size of the datatype lookup table version uint32 Protocol version (required) For Jelly 1.0.x value must be 1. For custom extensions, the value must be 1000 or higher. <p></p>"},{"location":"specification/reference/#rdfstreamrow","title":"RdfStreamRow","text":"<p>RDF stream row</p> Field Type Label Description options RdfStreamOptions Stream options. Must occur at the start of the stream. triple RdfTriple RDF triple statement. Valid in TRIPLES and GRAPHS streams. quad RdfQuad RDF quad statement. Only valid in a QUADS stream. graph_start RdfGraphStart Graph boundary: ends the currently transmitted graph and starts a new one Only valid in a GRAPHS stream. graph_end RdfGraphEnd Explicit end of a graph. Signals the consumer that the transmitted graph is complete. Only valid in a GRAPHS stream. name RdfNameEntry Entry in the name lookup table. prefix RdfPrefixEntry Entry in the prefix lookup table. datatype RdfDatatypeEntry Entry in the datatype lookup table. <p></p>"},{"location":"specification/reference/#rdfterm","title":"RdfTerm","text":"<p>RDF terms</p> Field Type Label Description iri RdfIri IRI bnode string Blank node literal RdfLiteral Literal triple_term RdfTriple RDF-star quoted triple repeat RdfRepeat Repeated term from the previous statement. Only valid in statements, not quoted triples. <p></p>"},{"location":"specification/reference/#rdftriple","title":"RdfTriple","text":"<p>RDF triple</p> Field Type Label Description s RdfTerm Triple subject p RdfTerm Triple predicate o RdfTerm Triple object <p></p>"},{"location":"specification/reference/#rdfstreamtype","title":"RdfStreamType","text":"<p>RDF stream type</p> Name Number Description RDF_STREAM_TYPE_UNSPECIFIED 0 Unspecified stream type \u2013 invalid RDF_STREAM_TYPE_TRIPLES 1 RDF triples RDF_STREAM_TYPE_QUADS 2 RDF quads RDF_STREAM_TYPE_GRAPHS 3 RDF triples grouped in graphs"},{"location":"specification/reference/#scalar-value-types","title":"Scalar Value Types","text":".proto Type Notes C++ Java Python Go C# PHP Ruby  double double double float float64 double float Float  float float float float float32 float float Float  int32 Uses variable-length encoding. Inefficient for encoding negative numbers \u2013 if your field is likely to have negative values, use sint32 instead. int32 int int int32 int integer Bignum or Fixnum (as required)  int64 Uses variable-length encoding. Inefficient for encoding negative numbers \u2013 if your field is likely to have negative values, use sint64 instead. int64 long int/long int64 long integer/string Bignum  uint32 Uses variable-length encoding. uint32 int int/long uint32 uint integer Bignum or Fixnum (as required)  uint64 Uses variable-length encoding. uint64 long int/long uint64 ulong integer/string Bignum or Fixnum (as required)  sint32 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int32s. int32 int int int32 int integer Bignum or Fixnum (as required)  sint64 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int64s. int64 long int/long int64 long integer/string Bignum  fixed32 Always four bytes. More efficient than uint32 if values are often greater than 2^28. uint32 int int uint32 uint integer Bignum or Fixnum (as required)  fixed64 Always eight bytes. More efficient than uint64 if values are often greater than 2^56. uint64 long int/long uint64 ulong integer/string Bignum  sfixed32 Always four bytes. int32 int int int32 int integer Bignum or Fixnum (as required)  sfixed64 Always eight bytes. int64 long int/long int64 long integer/string Bignum  bool bool boolean boolean bool bool boolean TrueClass/FalseClass  string A string must always contain UTF-8 encoded or 7-bit ASCII text. string String str/unicode string string string String (UTF-8)  bytes May contain any arbitrary sequence of bytes. string ByteString str []byte ByteString string String (ASCII-8BIT)"},{"location":"specification/serialization/","title":"Jelly serialization format specification","text":"<p>This document is the specification of the Jelly serialization format. It is intended for implementers of Jelly libraries and applications. If you are looking for a user-friendly introduction to Jelly, see the Jelly index page.</p> <p>This document is accompanied by the Jelly Protobuf reference and the Protobuf definition itself (<code>rdf.proto</code>).</p> <p>The following assumptions are used in this document:</p> <ul> <li>The basis for the terms used is the RDF 1.1 specification (W3C Recommendation 25 February 2014).</li> <li>In parts referring to RDF-star, the RDF-star draft specification (W3C Community Group Draft Report 29 June 2023) is used. As the scope in which the RDF-star specification is used here is minimal, later versions of the specification are expected to be compatible with this document.</li> <li>All strings in the serialization are assumed to be UTF-8 encoded.</li> </ul> <p>Author: Piotr Sowi\u0144ski (Ostrzyciel)</p> <p>Version: 1.0.0</p> <p>Document status: Draft specification</p> <p>Info</p> <p>The key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\",  \"MAY\", and \"OPTIONAL\" in this document are to be interpreted as described in RFC 2119.</p> <p>Note</p> <p>The \"Note\" blocks in this document are not part of the specification, but rather provide additional information for implementers.</p> <p>Note</p> <p>The \"Example\" blocks in this document are not part of the specification, but rather provide informal examples of the serialization format. The examples use the Protocol Buffers Text Format Language.</p>"},{"location":"specification/serialization/#conformance","title":"Conformance","text":"<p>Implementations MAY choose to implement only a subset of the following specification. In this case, they SHOULD clearly specify which parts of the specification they implement. In the rest of this specification, the keywords \"MUST\", \"MUST NOT\", etc. refer to full (not partial) implementations.</p> <p>Note</p> <p>Implementations may in particular choose to not implement features that are not supported on the target platform (e.g., RDF datasets, RDF-star, generalized RDF terms, etc.).</p> <p>Implementations MAY also choose to extend Jelly with additional features that SHOULD NOT interfere with the serialization being readable by implementations which follow the specification.</p>"},{"location":"specification/serialization/#versioning","title":"Versioning","text":"<p>The protocol follows the Semantic Versioning 2.0 scheme. Each MAJOR.MINOR semantic version corresponds to an integer version tag in the protocol. The version tag is encoded in the <code>version</code> field of the <code>RdfStreamOptions</code> message. See also the section on stream options for more information on how to handle the version tags in serialized streams.</p> <p>The following versions of the protocol are defined:</p> Version tag Semantic version 1 1.0.x (current) <p>Note</p> <p>Releases of the protocol are published on GitHub.</p>"},{"location":"specification/serialization/#backward-compatibility","title":"Backward compatibility","text":"<p>Implementations SHOULD ensure backward compatibility. To achieve backward compatibility, the implementation MUST be able to read all messages from the previous releases of the protocol with the same MAJOR version. The implementation MAY also be able to read messages from previous releases of the protocol with a different MAJOR version.</p> <p>Note</p> <p>The protocol is designed in such a way that you don't need to worry about backward compatibility. The only thing you need to do is to implement the latest version of the protocol, and you will automatically get backward compatibility with all previous versions (of the same MAJOR).</p>"},{"location":"specification/serialization/#forward-compatibility","title":"Forward compatibility","text":"<p>Forward compatibility is not guaranteed. Implementations MAY be able to read messages from future releases of the protocol with the same MAJOR version. Implementations MAY also be able to read messages from future releases of the protocol with a different MAJOR version.</p>"},{"location":"specification/serialization/#actors-and-implementations","title":"Actors and implementations","text":"<p>Jelly assumes there to be two actors involved in processing the stream: the producer (serializer) and the consumer (parser). The producer is responsible for serializing the RDF data into the Jelly format, and the consumer is responsible for parsing the Jelly format into RDF data.</p> <p>Implementations may include only the producer, only the consumer, or both.</p>"},{"location":"specification/serialization/#format-specification","title":"Format specification","text":"<p>The Jelly serialization format uses Protocol Buffers version 3 as the underlying serialization format. All implementations MUST use a compliant Protocol Buffers implementation. The Protocol Buffers schema for Jelly serialization is defined in <code>rdf.proto</code> (source code, reference).</p> <p>The Jelly format is a stream (i.e., an ordered sequence) of stream frames. The frames may be sent one-by-one using a dedicated streaming protocol (e.g., gRPC, MQTT, Kafka) or written in sequence to a byte stream (e.g., a file or socket). When writing to a byte stream, the frames MUST be delimeted \u2013 see the delimited variant.</p> <p>Jelly supports several distinct types of streams, and uses a simple and configurable compression mechanism using lookup tables.</p>"},{"location":"specification/serialization/#stream-frames","title":"Stream frames","text":"<p>A stream frame is a message of type <code>RdfStreamFrame</code> (reference). The message has only one field (<code>rows</code>), which is a repeated field of type <code>RdfStreamRow</code> (reference). A stream frame may contain any number of rows, however it is RECOMMENDED to keep the size of the frames below 1 MB. The semantics for the frames are not defined by the protocol. The end users are free to define their own semantics for the frames.</p> <p>Note</p> <p>A stream frame in \"simple flat file\" is just a batch of RDF statements \u2013 the stream frames may carry no semantics in this case. You can make the stream frame as long as the file itself, but this is not recommended, as it would make the file harder to process.</p> <p>Note</p> <p>Stream frames can also be used to indicate individual stream elements. For example, in the case of a stream of RDF datasets, each frame may contain one dataset. RiverBench datasets use this convention in their distributions.</p>"},{"location":"specification/serialization/#ordering","title":"Ordering","text":"<p>Stream frames MUST be processed strictly in order to preserve the semantics of the stream. Each stream frame MUST be processed in its entirety before the next stream frame is processed.</p> <p>Implementations MAY choose to adopt a non-standard solution where the order or delivery of the frames is not guaranteed and the stream can be read in more than one order or without some frames. The implementation MUST clearly specify in the documentation that it uses such a non-standard solution.</p> <p>Note</p> <p>An example where not adhering to the strict ordering may be useful is when you are dealing with a network streaming protocol that does not guarantee the order of the messages (e.g., MQTT).</p> <p>Note</p> <p>The main thing you will need to worry about is the order of the lookup tables. If you can, emit all lookup tables at the beginning of the stream. When using stream partitions (e.g., in Kafka), you should ensure that the lookups are emitted to each partition. Alternatively, you can transmit the lookup tables separately from the stream.</p>"},{"location":"specification/serialization/#stream-rows","title":"Stream rows","text":"<p>A stream row is a message of type <code>RdfStreamRow</code>. It has one of the following fields set:</p> <ul> <li><code>options</code> (1) \u2013 stream options header, indicating the compression options and the used RDF features in the stream.</li> <li><code>triple</code> (2) \u2013 RDF triple statement. It MUST NOT appear in streams of type other than <code>RDF_STREAM_TYPE_TRIPLES</code> or <code>RDF_STREAM_TYPE_GRAPHS</code>.</li> <li><code>quad</code> (3) \u2013 RDF quad statement. It MUST NOT appear in streams of type other than <code>RDF_STREAM_TYPE_QUADS</code>.</li> <li><code>graph_start</code> (4) \u2013 indicates the start of a graph (named or default). It MUST NOT appear in streams of type other than <code>RDF_STREAM_TYPE_GRAPHS</code>.</li> <li><code>graph_end</code> (5) \u2013 indicates the end of a graph (named or default). It MUST NOT appear in streams of type other than <code>RDF_STREAM_TYPE_GRAPHS</code>.</li> <li><code>name</code> (9) \u2013 entry in the name lookup.</li> <li><code>prefix</code> (10) \u2013 entry in the prefix lookup.</li> <li><code>datatype</code> (11) \u2013 entry in the datatype lookup.</li> </ul> <p>Stream rows MUST be processed strictly in order to preserve the semantics of the stream.</p>"},{"location":"specification/serialization/#stream-types","title":"Stream types","text":"<p>The type of the stream MUST be explicitly specified in the (stream options header)[#stream-options]. The type of the stream is defined by the <code>RdfStreamType</code> enum (reference). The following types are defined:</p> <ul> <li><code>RDF_STREAM_TYPE_UNSPECIFIED</code> (0) \u2013 default value. This stream type MUST NOT be used. The implementations SHOULD treat this value as an error.</li> <li><code>RDF_STREAM_TYPE_TRIPLES</code> (1) \u2013 stream of RDF triple statements. Each stream frame (or the entire stream) corresponds to an RDF graph. In this case, the stream MUST NOT contain <code>RdfStreamRow</code> messages with the <code>quad</code>, <code>graph_start</code>, or <code>graph_end</code> fields set.</li> <li><code>RDF_STREAM_TYPE_QUADS</code> (2) \u2013 stream of RDF quad statements (same as simple statements in N-Quads). Each stream frame (or the entire stream) corresponds to an RDF dataset. In this case, the stream MUST NOT contain <code>RdfStreamRow</code> messages with the <code>triple</code>, <code>graph_start</code>, or <code>graph_end</code> fields set.</li> <li><code>RDF_STREAM_TYPE_GRAPHS</code> (3) \u2013 stream of RDF graphs (named or default). Each stream frame (or the entire stream) corresponds to an RDF dataset. In this case, the stream MUST NOT contain <code>RdfStreamRow</code> messages with the <code>quad</code> fields set.</li> </ul> <p>Note</p> <p>See also a more human explanation of the available stream types.</p>"},{"location":"specification/serialization/#stream-options","title":"Stream options","text":"<p>The stream options is a message of type <code>RdfStreamOptions</code> (reference). It MUST be the first row in the stream. It MAY appear more than once in the stream (also after other rows), but it MUST be identical to all previous occurrences. Implementations MAY throw an error if the stream options header is not present at the start of the stream, alternatively, they MAY use the default options. Implementations SHOULD NOT throw an error if the stream options header is present more than once in the stream.</p> <p>The stream options header instructs the consumer of the stream (parser) on the size of the needed lookups to decode the stream and the features used by the stream.</p> <p>The stream options header contains the following fields:</p> <ul> <li><code>stream_name</code> (1) \u2013 name of the stream. This field is OPTIONAL and its use is not defined by the protocol. It MAY be used to identify the stream.</li> <li><code>stream_type</code> (2) \u2013 type of the stream. This field is REQUIRED.</li> <li><code>generalized_statements</code> (3) \u2013 whether the stream contains generalized RDF triples or graphs. This field MUST be set to true if the stream contains generalized RDF triples or graphs. It SHOULD NOT be set to true if the stream does not use this feature. This field is OPTIONAL and defaults to false.</li> <li><code>use_repeat</code> (4) \u2013 whether the stream uses repeated terms compression. This field MUST be set to true if the stream uses repeated terms. It SHOULD NOT be set to true if the stream does not use this feature. This field is OPTIONAL and defaults to false.</li> <li><code>rdf_star</code> (5) \u2013 whether the stream uses RDF-star (quoted triples). This field MUST be set to true if the stream uses RDF-star. It SHOULD NOT be set to true if the stream does not use this feature. This field is OPTIONAL and defaults to false.</li> <li><code>max_name_table_size</code> (9) \u2013 maximum size of the name lookup. This field is OPTIONAL and defaults to 0 (no lookup). If the field is set to 0, the name lookup MUST NOT be used in the stream. If the field is set to a positive value, the name lookup SHOULD be used in the stream and the size of the lookup MUST NOT exceed the value of this field.</li> <li><code>max_prefix_table_size</code> (10) \u2013 maximum size of the prefix lookup. This field is OPTIONAL and defaults to 0 (no lookup). If the field is set to 0, the prefix lookup MUST NOT be used in the stream. If the field is set to a positive value, the prefix lookup SHOULD be used in the stream and the size of the lookup MUST NOT exceed the value of this field.</li> <li><code>max_datatype_table_size</code> (11) \u2013 maximum size of the datatype lookup. This field is OPTIONAL and defaults to 0 (no lookup). If the field is set to 0, the datatype lookup MUST NOT be used in the stream (which effectively prohibits the use of datatype literals). If the field is set to a positive value, the datatype lookup SHOULD be used in the stream and the size of the lookup MUST NOT exceed the value of this field.</li> <li><code>version</code> (15) \u2013 version tag of the stream. This field is REQUIRED.<ul> <li>The version tag is encoded as a varint. The version tag MUST be greater than 0.</li> <li>The producer of the stream MUST set the version tag to the version tag of the implementation.</li> <li>The consumer SHOULD throw an error if the version tag is greater than the version tag of the implementation.</li> <li>The consumer SHOULD throw an error if the version tag is zero.</li> <li>The consumer SHOULD NOT throw an error if the version tag is not zero but lower than the version tag of the implementation.</li> <li>The producer may use version tags greater than 1000 to indicate non-standard versions of the protocol.</li> </ul> </li> </ul>"},{"location":"specification/serialization/#prefix-name-and-datatype-lookups","title":"Prefix, name, and datatype lookups","text":"<p>Jelly uses a common mechanism of lookup tables for IRI prefixes, IRI names (postfixes), and datatypes. The lookups are used to compress the IRIs and datatypes in the stream. All lookups function in the same way:</p> <ul> <li>The lookup is a map from a varint to a valid UTF-8 string.</li> <li>The lookup can be modified at any point in the stream. The modification consists of setting the lookup for a given varint to a given string. The modification MUST be applied to all subsequent rows in the stream.</li> <li>The first use of a given lookup element MUST be after it is defined in the lookup. If the consumer encounters a lookup element that is not defined in the lookup, it SHOULD throw an error.</li> <li>The lookups are indexed from 1. The default value of 0 MUST NOT be used as a key in the lookup.</li> <li>The maximum size of the lookup is communicated at the start of the stream (see stream options header). The producer of the stream MUST NOT exceed the maximum size of the lookup. The consumer of the stream MAY implement the lookup as a fixed-size array, or extend it dynamically.</li> <li>The lookup is updated with different messages, depending on the type of the lookup:<ul> <li><code>RdfNameEntry</code> for the name lookup,</li> <li><code>RdfPrefixEntry</code> for the prefix lookup,</li> <li><code>RdfDatatypeEntry</code> for the datatype lookup.</li> </ul> </li> <li>The producer may use any strategy to update the lookup.</li> </ul> <p>Note</p> <p>The spec does not specify what strategy should the producer use to update the lookup. You can use a the LRU strategy (as used in the Scala implementation), LFU, or something more complex. You can also have a fixed lookup in the producer and communicate it at the start of the stream. This is possible if you are using a fixed set of prefixes, names, or datatypes and want to conserve computing power (e.g., in IoT devices).</p> <p>The simplest way to implement the consumer's lookup is to just use an indexed array of fixed size. The workload on the consumer's side is much lower than on the producer's side, so your choice of the strategy depends largely on the producer.</p>"},{"location":"specification/serialization/#rdf-statements-and-graphs","title":"RDF statements and graphs","text":"<p>RDF statements (triples or quads) are communicated in three different ways, depending on the type of the stream:</p> <ul> <li><code>RDF_STREAM_TYPE_TRIPLES</code> \u2013 triples are encoded using <code>RdfTriple</code> messages.<ul> <li><code>RdfTriple</code> has three fields: <code>s</code>, <code>p</code>, <code>o</code>, corresponding to the subject, predicate, and object of the triple. All of these fields are RDF terms and are REQUIRED.</li> </ul> </li> <li><code>RDF_STREAM_TYPE_QUADS</code> \u2013 quads are encoded using <code>RdfQuad</code> messages.<ul> <li><code>RdfQuad</code> has four fields: <code>s</code>, <code>p</code>, <code>o</code>, <code>g</code>, corresponding to the subject, predicate, object, and graph of the quad. The <code>s</code>, <code>p</code>, <code>o</code> are RDF terms and are REQUIRED. The <code>g</code> field is an RDF graph node and is REQUIRED.</li> </ul> </li> <li><code>RDF_STREAM_TYPE_GRAPHS</code> \u2013 graphs are encoded using <code>RdfGraphStart</code> and <code>RdfGraphEnd</code> messages. Triples between the start and end of the graph are encoded using <code>RdfTriple</code> messages. If a triple is between the start and end of the graph, it is considered to be in the graph.<ul> <li>In this type of stream, triples MUST NOT occur outside of a graph. If a triple is encountered outside a graph, the consumer SHOULD throw an error.</li> <li>A graph start MUST NOT occur inside another graph. If a graph start is encountered inside another graph, the consumer SHOULD throw an error.</li> <li>A graph end MUST NOT occur outside a graph. If a graph end is encountered outside a graph, the consumer MAY throw an error.</li> <li>A graph MAY be empty (i.e., it may contain no triples).</li> <li>A graph corresponding to one graph node MAY occur multiple times in a stream or a stream frame. The consumer MUST treat all occurrences of the graph as a single RDF graph.</li> <li>A graph MAY span more than one stream frame. The consumer MUST treat the graph spanning several stream frames as a single RDF graph.</li> </ul> </li> </ul> <p>Note</p> <p>If the stream is meant to represent a single RDF dataset, then the graphs should be able to stretch across several stream frames. If the stream is meant to represent a stream of RDF datasets, then the graphs should be contained within a single stream frame.</p>"},{"location":"specification/serialization/#rdf-terms","title":"RDF terms","text":"<p>RDF terms are encoded using the <code>RdfTerm</code> message. The message has one of the following fields set: <code>iri</code>, <code>bnode</code>, <code>literal</code>, <code>triple_term</code>, <code>repeat</code>, corresponding to RDF IRIs, blank nodes, literals, RDF-star quoted triples, and repeated terms, respectively. Exactly one of these fields MUST be set.</p>"},{"location":"specification/serialization/#iris","title":"IRIs","text":"<p>The IRIs are encoded using the <code>RdfIri</code> message. The message has two fields that together make up the IRI:</p> <ul> <li><code>prefix_id</code> (1) \u2013 1-based index of the prefix of the IRI, corresponding to an entry in the prefix lookup. This field is OPTIONAL and the default value (0) indicates an empty prefix.</li> <li><code>name_id</code> (2) \u2013 1-based index of the name (suffix) of the IRI, corresponding to an entry in the name lookup. This field is OPTIONAL and the default value (0) indicates an empty name.</li> </ul> <p>At least one of the <code>prefix_id</code> and <code>name_id</code> fields MUST be set to a non-default, positive value. The IRI is then constructed by concatenating the prefix and the name. The IRI SHOULD be a valid IRI, as defined in RFC 3987.</p> Example (click to expand) <p>Assume the following lookup entries were defined in the stream (wrapping <code>RdfStreamRow</code>s were omitted for brevity):</p> <pre><code>RdfPrefixEntry {\n    id: 1\n    prefix: \"http://example.com/\"\n}\nRdfNameEntry {\n    id: 4\n    name: \"example\"\n}\nRdfNameEntry {\n    id: 1\n    name: \"http://test.com/test\"\n}\n</code></pre> <p>Then the following IRIs are encoded as follows:</p> <pre><code># http://example.com/example\nRdfIri {\n    prefix_id: 1\n    name_id: 4\n} \n\n# http://example.com/\nRdfIri {\n    prefix_id: 1\n}\n\n# http://test.com/test\nRdfIri {\n    name_id: 1\n}\n</code></pre> <p>Note</p> <p>The spec does not specify how to split the IRIs into names and prefixes. You can use any strategy you want, as long as you follow the rules above. The simplest way is to split the IRI at the last occurrence of the <code>#</code> or <code>/</code> character \u2013 this is what the Scala implementation uses. The prefixes are not meant to be user-facing, but you can also use user-defined prefixes (e.g., <code>@prefix</code> in Turtle) to split the IRIs.</p>"},{"location":"specification/serialization/#blank-nodes","title":"Blank nodes","text":"<p>RDF blank nodes are represented using simple strings. The string is the identifier of the blank node. The identifier may be any valid UTF-8 string.</p> <p>Because the spec does not define the semantics of the stream frames, blank node identifiers are not guaranteed to be unique across the stream frames. The consumer MAY choose to treat the blank nodes as unique across the stream (and thus treat all occurences of the identifier as a single node), or it MAY choose to treat them as unique only within a single stream frame. The producer SHOULD specify in the documentation which strategy it uses.</p> <p>Note</p> <p>If the stream is meant to represent a single RDF graph or dataset, then the blank node identifiers should be unique across the stream so that you can refer to them across stream frame boundaries. If the frames refer to different graphs or datasets, then the blank node identifiers should be unique only within a single frame.</p> <p>Note</p> <p>Many RDF libraries (e.g., RDF4J, Apache Jena) use internal identifiers for blank nodes, which can be used as the identifiers in Jelly streams. You can also use a different format, for example with shorter identifiers to preserve space.</p>"},{"location":"specification/serialization/#literals","title":"Literals","text":"<p>RDF literals are represented using the <code>RdfLiteral</code> message (reference). The message has the following fields:</p> <ul> <li><code>lex</code> (1) \u2013 the lexical form of the literal in UTF-8. This field is OPTIONAL and defaults to an empty string.</li> <li><code>literalKind</code> oneof. This field is REQUIRED and exactly one of the following fields MUST be set:<ul> <li><code>simple</code> (2) \u2013 empty message of type <code>RdfLiteralSimple</code> indicating that the literal is a simple literal (has datatype IRI equal to <code>http://www.w3.org/2001/XMLSchema#string</code>).</li> <li><code>langtag</code> (3) \u2013 UTF-8 language tag, indicating that the literal is a language-tagged string (has datatype IRI equal to <code>http://www.w3.org/1999/02/22-rdf-syntax-ns#langString</code>). The language tag SHOULD be a valid BCP 47 language tag.</li> <li><code>datatype</code> (4) \u2013 1-based index of the datatype in the datatype lookup, indicating that the literal is a typed literal. The value of this field MUST be greater than 0 and it MUST correspond to a valid entry in the datatype lookup.</li> </ul> </li> </ul>"},{"location":"specification/serialization/#quoted-triples-rdf-star","title":"Quoted triples (RDF-star)","text":"<p>RDF-star quoted triples are represented using the <code>RdfTriple</code> message (reference). Quoted triples are encoded in the same manner as triple statements, with the only difference being that repeated terms (<code>RdfRepeat</code>) MUST NOT be used in quoted triples. The consumer SHOULD throw an error if a repeated term is encountered in a quoted triple.</p> <p>Quoted triples may be nested up to arbitrary depth. The consumer SHOULD throw an error if the depth of the nesting exceeds the capabilities of the implementation.</p>"},{"location":"specification/serialization/#repeated-terms","title":"Repeated terms","text":"<p>Repeated terms indicate that a term in a given position (subject, predicate, object, or graph node in quads) is the same as the term in the same position in the previous row. The repeated terms are encoded using the <code>RdfRepeat</code> message (reference). The message does not have any fields.</p> <ul> <li>Repeated terms MUST NOT occur in quoted triples.</li> <li>Repeated terms MUST NOT occur in the first statement row of the stream.</li> <li>Repeated terms MAY occur in the first statement row of a stream frame. In this case, the repeated terms MUST be interpreted as repeated from the previous stream frame.</li> <li>A repeated term in a given position MAY occur after a repeated term. The consumer MUST interpret all consecutive appearances of the repeated term as the same term.</li> </ul> Example (click to expand) <p>In the example the wrapping <code>RdfStreamRow</code>s were omitted for brevity:</p> <pre><code># First row\nRdfTriple {\n    s: RdfTerm {\n        iri: RdfIri {\n            prefix_id: 1\n            name_id: 1\n        }\n    }\n    p: RdfTerm {\n        iri: RdfIri {\n            prefix_id: 1\n            name_id: 2\n        }\n    }\n    o: RdfTerm {\n        bnode: \"b1\"\n    }\n}\n\n# Second row \u2013 repeating the subject and predicate\nRdfTriple {\n    s: RdfRepeat {} # RdfTerm(iri: RdfIri(1, 1))\n    p: RdfRepeat {} # RdfTerm(iri: RdfIri(1, 2))\n    o: RdfTerm {\n        bnode: \"b2\"\n    }\n}\n\n# Third row \u2013 repeating the subject and object\nRdfTriple {\n    s: RdfRepeat {} # RdfTerm(iri: RdfIri(1, 1))\n    p: RdfTerm {\n        iri: RdfIri {\n            prefix_id: 2\n            name_id: 3\n        }\n    }\n    o: RdfRepeat {} # RdfTerm(bnode = \"b2\")\n}\n</code></pre> <p>Note</p> <p>Repeated terms can be simply implemented with four variables (s, p, o, g) holding the last non-repeated value of a term in that position. This O(1) solution is what the Scala implementation uses.</p> <p>Note</p> <p>Although repeated terms can stretch across stream frame boundaries (i.e., refer to values last seen in the previous stream frame), you don't have to use this feature. If your use case requires the stream frames to be more independent of each other (see: stream frame ordering), you can just reset the repeated terms at the start of each stream frame.</p>"},{"location":"specification/serialization/#rdf-graph-nodes","title":"RDF graph nodes","text":"<p>RDF graph nodes are encoded using the <code>RdfGraph</code> message. The message is used both in the <code>RdfGraphStart</code> message for GRAPHS streams and in the <code>RdfQuad</code> message for QUADS streams. The message MUST have exactly one of the following fields set:</p> <ul> <li><code>iri</code> (1) \u2013 the graph node is an IRI. The field is of type <code>RdfIri</code> (see: RDF terms \u2013 IRIs).</li> <li><code>bnode</code> (2) \u2013 the graph node is a blank node. The field is of type <code>string</code> (see: RDF terms \u2013 blank nodes).</li> <li><code>literal</code> (3) \u2013 the graph node is a literal. The field is of type <code>RdfLiteral</code> (see: RDF terms \u2013 literals). This field is only valid for generalized RDF streams (see: stream options header).</li> <li><code>default_graph</code> (4) \u2013 the graph node is the default graph. The field is of type <code>RdfDefaultGraph</code>, which is an empty message.</li> <li><code>repeat</code> (10) \u2013 the graph node is the same as in the previous row. The field is of type <code>RdfRepeat</code> (see: repeated terms). This field is only valid for QUADS streams, within the <code>RdfQuad</code> message. It MUST NOT occur within the <code>RdfGraphStart</code> message.</li> </ul>"},{"location":"specification/serialization/#delimited-variant-of-jelly","title":"Delimited variant of Jelly","text":"<p>Note</p> <p>Protobuf messages are not delimited, so if you write multiple messages to the same file / socket / byte stream, you need to add some kind of delimiter between them. Jelly uses the convention already implemented in some protobuf libraries of prepending a varint before the message, to specify the length of the message. </p> <p>A byte stream (or file) in the delimited variant MUST consist of a series of delimited <code>RdfStreamFrame</code> messages. A delimited message is a message that has a varint prepended before it, specifying the length of the message in bytes.</p> <p>Implementing the delimited variant is OPTIONAL.</p>"},{"location":"specification/serialization/#delimited-variant-implementations","title":"Delimited variant implementations","text":"<p>The delimiting convention is implemented in Protobuf libraries for:</p> <ul> <li>C++: delimited_message_util.cc</li> <li>Java / Scala: writeDelimitedTo and parseDelimitedFrom</li> </ul> <p>The JVM (Scala) implementation of Jelly also supports the delimited variant \u2013 see the documentation.</p>"},{"location":"specification/serialization/#internet-media-type-and-file-extension","title":"Internet media type and file extension","text":"<p>The RECOMMENDED media type for Jelly is <code>application/x-jelly-rdf</code>. The RECOMMENDED file extension is <code>.jelly</code>.</p> <p>The files SHOULD be saved in the delimited variant of Jelly.</p>"},{"location":"specification/serialization/#implementations","title":"Implementations","text":"<p>This section is not part of the specification.</p> <p>The following implementations of the Jelly serialization format specification are available:</p> <ul> <li>Jelly JVM (Scala) implementation<ul> <li>Specification version: 1.0.0</li> <li>Implemented actors: producer, consumer</li> <li>Conformance: full</li> <li>Supported RDF libraries: Apache Jena, RDF4J</li> </ul> </li> </ul>"},{"location":"specification/streaming/","title":"Jelly gRPC streaming protocol specification","text":"<p>This document is the specification of the Jelly gRPC streaming protocol (publish/subscribe mechanism). It is intended for implementers of Jelly libraries and applications. If you are looking for a user-friendly introduction to Jelly, see the Jelly index page.</p> <p>This document is accompanied by the Jelly Protobuf reference and the Protobuf definition itself (<code>grpc.proto</code>).</p> <p>The following assumptions are used in this document:</p> <ul> <li>This document uses the specification for the Jelly serialization format.</li> <li>All strings in the mentioned Protobuf messages are assumed to be UTF-8 encoded.</li> <li>Standard gRPC status codes are used, as defined in gRPC documentation.</li> </ul> <p>Author: Piotr Sowi\u0144ski (Ostrzyciel)</p> <p>Version: 1.0.0</p> <p>Document status: Draft specification</p> <p>Info</p> <p>The key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\",  \"MAY\", and \"OPTIONAL\" in this document are to be interpreted as described in RFC 2119.</p> <p>Note</p> <p>The \"Note\" blocks in this document are not part of the specification, but rather provide additional information for implementers.</p> <p>Note</p> <p>The \"Example\" blocks in this document are not part of the specification, but rather provide informal examples of the serialization format. The examples use the Protocol Buffers Text Format Language.</p>"},{"location":"specification/streaming/#conformance","title":"Conformance","text":"<p>Implementations MAY choose to implement only a subset of the following specification. In this case, they SHOULD clearly specify which parts of the specification they implement. In the rest of this specification, the keywords \"MUST\", \"MUST NOT\", etc. refer to full (not partial) implementations.</p>"},{"location":"specification/streaming/#versioning","title":"Versioning","text":"<p>The streaming protocol follows the Semantic Versioning 2.0 scheme. The version of the gRPC streaming protocol is equal to the version of the corresponding serialization format (1:1 equivalence). The version of the protocol is specified in the stream options \u2013 see the serialization specification for details.</p> <p>Note</p> <p>Releases of the protocol are published on GitHub.</p>"},{"location":"specification/streaming/#backward-compatibility","title":"Backward compatibility","text":"<p>Implementations SHOULD ensure backward compatibility. To achieve backward compatibility, the implementation MUST be able to respond to all RPCs from the previous releases of the protocol with the same MAJOR version. The implementation MAY also be able to respond to RPCs from previous releases of the protocol with a different MAJOR version.</p> <p>Note</p> <p>The protocol is designed in such a way that you don't need to worry about backward compatibility. The only thing you need to do is to implement the latest version of the protocol, and you will automatically get backward compatibility with all previous versions (of the same MAJOR).</p>"},{"location":"specification/streaming/#forward-compatibility","title":"Forward compatibility","text":"<p>Forward compatibility is not guaranteed. Implementations MAY be able to respond to RPCs from future releases of the protocol with the same MAJOR version. Implementations MAY also be able to respond to RPCs from future releases of the protocol with a different MAJOR version.</p>"},{"location":"specification/streaming/#actors-and-implementations","title":"Actors and implementations","text":"<p>The Jelly gRPC streaming protocol assumes there to be two actors: the server and the client. These actors can both play the role of the producer or the consumer of the stream (see serialization specification), depending on the direction of the stream.</p> <p>Implementations may include only the server, only the client, or both.</p>"},{"location":"specification/streaming/#protocol-specification","title":"Protocol specification","text":"<p>The protocol specifies a simple publish/subscribe mechanism topics identified with UTF-8 strings. The client can subscribe to a topic and receive messages published to that topic by the server. The client can also publish messages to a topic.</p> <p>The described protocol is implemented as a gRPC service <code>RdfStreamService</code> (reference).</p> <p>Note</p> <p>The protocol does not specify what happens to the messages on the server \u2013 this is NOT a broker or message queue specification. The protocol is meant to enable point-to-point communication, but can also be used to implement a broker or a similar service (see Usage notes below).</p> <p>You can also ignore the topics and use the protocol as a simple streaming protocol.</p>"},{"location":"specification/streaming/#topics","title":"Topics","text":"<p>Topics are identified with UTF-8 strings. The topic string MUST be valid UTF-8. There are no further restrictions on the topic string.</p> <p>Note</p> <p>The topic can be whatever you like \u2013 it can also be empty. It is up the user to decide what to use the topics for, or if to use them at all.</p>"},{"location":"specification/streaming/#subscribing-to-a-stream","title":"Subscribing to a stream","text":"<p>The client subscribes to a stream from the server with the <code>SubscribeRdf</code> RPC (reference). The RPC is initiated with an <code>RdfStreamSubscribe</code> message (reference) from the client. The message includes two OPTIONAL fields:</p> <ul> <li><code>topic</code> (1) \u2013 the topic to subscribe to. The default is an empty string.</li> <li><code>options</code> (2) \u2013 the stream options (<code>RdfStreamOptions</code>). The default is an empty message.</li> </ul> <p>The server MUST respond with either a stream of <code>RdfStreamFrame</code> messages or an error.</p>"},{"location":"specification/streaming/#stream-options-handling","title":"Stream options handling","text":"<p>The client MAY request specific options for the stream it subscribes to. In that case, the client MUST include the <code>options</code> field in the <code>RdfStreamSubscribe</code> message. The server SHOULD respond with a stream that uses options that are compatible with the options requested by the client. If the server cannot respond with a stream that uses options that are compatible with the options requested by the client, the server MUST respond with the <code>INVALID_ARGUMENT</code> error.</p> <p>The following rules are used to determine if the options are compatible. All rules MUST be satisfied for the options to be compatible.</p> Option Client request Server response <code>stream_name</code> <code>x</code> MAY be <code>x</code> <code>stream_type</code> <code>x</code> MUST be <code>x</code> <code>generalized_statements</code> <code>x</code> MUST be <code>x</code> or false <code>use_repeat</code> <code>x</code> MUST be <code>x</code> or false <code>rdf_star</code> <code>x</code> MUST be <code>x</code> or false <code>max_name_table_size</code> <code>x</code> MUST be &lt;= <code>x</code> <code>max_prefix_table_size</code> <code>x</code> MUST be &lt;= <code>x</code> <code>max_datatype_table_size</code> <code>x</code> MUST be &lt;= <code>x</code> <code>version</code> <code>x</code> MUST be &lt;= <code>x</code> <p>Notes</p> <p>The server should implement some limits for the stream options it supports, for example the maximum size of the name table. Otherwise, a client may request a name table that takes up all the server's memory.</p>"},{"location":"specification/streaming/#publishing-a-stream","title":"Publishing a stream","text":"<p>The client publishes a stream to the server with the <code>PublishRdf</code> RPC (reference). The RPC is initiated with a stream of <code>RdfStreamFrame</code> messages from the client. The stream MUST include at least one message. The first frame MUST include a row with the stream options as the first row. After the stream successfully completes, the server MUST respond with the <code>RdfStreamReceived</code> message (reference).</p> <p>If the server cannot handle the stream with the specified options, the server MUST respond with the <code>INVALID_ARGUMENT</code> error.</p>"},{"location":"specification/streaming/#usage-notes","title":"Usage notes","text":"<p>This section is not part of the specification.</p> <p>The protocol is deliberately very general and unrestrictive. The pub/sub mechanism can be used in a number of ways, possibly extending the existing base protocol. The following are some examples of how the protocol can be used:</p> <ul> <li>Server publishing a number of streams, each with a different topic.</li> <li>RDF stream broker or message queue \u2013 the server acts as a \"hub\" aggregating RDF data sent to a topic by clients, and then forwarding it to other clients.</li> <li>Microservice chains \u2013 one service can process an RDF stream, forward it to another service, etc.</li> </ul> <p>These use cases can be implemented with the protocol as-is, or by extending the protocol with additional messages and/or RPCs. In either case, the protocol provides a base layer for compatibility between different implementations.</p>"},{"location":"specification/streaming/#implementations","title":"Implementations","text":"<p>This section is not part of the specification.</p> <p>The following implementations of the Jelly gRPC streaming protocol specification are available:</p> <ul> <li>Jelly JVM (Scala) implementation<ul> <li>Specification version: 1.0.0</li> <li>Partial (boilerplate) implementation based on Apache Pekko gRPC. Requires the end user to implement their own code for handling the streams.</li> </ul> </li> </ul>"}]}